#LyX 2.4 created this file. For more info see https://www.lyx.org/
\lyxformat 620
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass optbook
\use_default_options true
\maintain_unincluded_children no
\language english
\language_package default
\inputencoding auto-legacy
\fontencoding auto
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_roman_osf false
\font_sans_osf false
\font_typewriter_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_formatted_ref 0
\use_minted 0
\use_lineno 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tablestyle default
\tracking_changes false
\output_changes false
\change_bars false
\postpone_fragile_content false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\docbook_table_output 0
\docbook_mathml_prefix 1
\end_header

\begin_body

\begin_layout Section
Philosophy
\end_layout

\begin_layout Standard
Optimization methods often follow the following framework:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithm2e}[H]
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
caption{
\end_layout

\end_inset


\begin_inset Formula $\mathtt{OptimizationFramework}$
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
SetAlgoLined
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
For{
\end_layout

\end_inset


\begin_inset Formula $k=0,1,\cdots$
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}{
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Approximate 
\begin_inset Formula $f$
\end_inset

 by a simpler function 
\begin_inset Formula $f_{k}$
\end_inset

 according to the current point 
\begin_inset Formula $x^{(k)}$
\end_inset


\end_layout

\begin_layout Standard
Do something using 
\begin_inset Formula $f_{k}$
\end_inset

 (such as set 
\begin_inset Formula $x^{(k+1)}=\arg\min_{x}f_{k}(x)$
\end_inset

)
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{algorithm2e}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The runtime depends on the number of iterations and the cost per iteration.
 Philosophically,
 the difficulties of a problem can never be created nor destroyed,
 only converted from one form of difficulty to another.
 When we decrease the number of iterations,
 the cost per iteration often increases.
 The gain of new methods often come from avoiding some wasted computation,
 utilizing some forgotten information or giving a faster but tailored algorithm for a sub-problem.
 This is of course just an empirical observation.
\end_layout

\begin_layout Standard
One key question to answer in designing an optimization algorithm is what the problem looks like (or how can we approximate 
\begin_inset Formula $f$
\end_inset

 by a simpler function).
 Here are some approximations we will use in this textbook:
\end_layout

\begin_layout Itemize
First-order Approximation:
 
\begin_inset Formula $f(y)\approx f(x)+\left\langle \nabla f(x),y-x\right\rangle $
\end_inset

 (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Gradient-Descent"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Itemize
Second-order Approximation:
 
\begin_inset Formula $f(y)\approx f(x)+\left\langle \nabla f(x),y-x\right\rangle +(y-x)^{\top}\nabla^{2}f(x)(y-x)$
\end_inset

 (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Newton-Method"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Itemize
Stochastic/Monte-Carlo Approximation:
 
\begin_inset Formula $\sum_{i}f_{i}(x)\approx f_{j}(x)$
\end_inset

 for a random 
\begin_inset Formula $j$
\end_inset

 (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Stochastic-Gradient-Descent"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Itemize
Matrix Approximation:
 Approximate 
\begin_inset Formula $A$
\end_inset

 by a simpler 
\begin_inset Formula $B$
\end_inset

 with 
\begin_inset Formula $\frac{1}{2}A\preceq B\preceq2A$
\end_inset

 (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Subspace-embedding"
nolink "false"

\end_inset

 and Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Leverage-Score-Sampling"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Itemize
Matrix Approximation:
 Approximate 
\begin_inset Formula $A$
\end_inset

 by a low-rank matrix.
\end_layout

\begin_layout Itemize
Set Approximation:
 Approximate a convex set by an ellipsoid or a polytope (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Cutting-Plane-Methods"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Itemize
Barrier Approximation:
 Approximate a convex set by a smooth function that blows up on the boundary (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:IPM"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Itemize
Polynomial Approximation:
 Approximate a function by a polynomial (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Chebyshev-Polynomials"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Itemize
Partial Approximation:
 Split the problem into two parts and approximate only one part.
\end_layout

\begin_layout Itemize
Taylor Approximation:
 
\begin_inset Formula $f(y)\approx\sum_{k=0}^{K}D^{k}f(x)[y-x]^{k}/k!$
\end_inset

 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Cite
\end_layout

\end_inset

.
\end_layout

\begin_layout Itemize
Mixed 
\begin_inset Formula $\ell^{2}$
\end_inset

-
\begin_inset Formula $\ell^{p}$
\end_inset

 Approximation:
 
\begin_inset Formula $f(y)\approx f(x)+\left\langle \nabla f(x),y-x\right\rangle +\sum_{i=1}^{n}(\alpha_{i}(y_{i}-x_{i})^{2}+\beta_{i}(y_{i}-x_{i})^{p})$
\end_inset

 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Cite
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Here are other approximations not covered:
\end_layout

\begin_layout Itemize
Stochastic Matrix Approximation:
 Approximate 
\begin_inset Formula $A$
\end_inset

 by a simpler random 
\begin_inset Formula $B$
\end_inset

 with 
\begin_inset Formula $B\preceq2A$
\end_inset

 and 
\begin_inset Formula $\E(B)\succeq\frac{1}{2}A$
\end_inset

 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Cite
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Homotopy Method:
 Approximate a function by a family of functions 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Cite
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
...(Please give me more examples here)...
\begin_inset Note Note
status open

\begin_layout Plain Layout
Santosh,
 add more stuff here
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The second question to answer is how to maintain different approximations created in different steps.
 One simple way would be forget the approximation we got in previous steps,
 but this is often not optimal.
 Another way is to keep all previous approximations/information (such as Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Cutting-Plane-Methods"
nolink "false"

\end_inset

).
 Often the best way will be combining previous and current approximation carefully to a better approximation (such as Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Accelerated-Gradient-Descent"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Section
Basic Algorithm
\begin_inset CommandInset label
LatexCommand label
name "sec:Gradient-Descent"

\end_inset


\end_layout

\begin_layout Standard
Perhaps the most natural algorithm for optimization is gradient descent.
 In fact,
 it has many variants with different guarantees.
 Assume that the function 
\begin_inset Formula $f$
\end_inset

 to be optimized is continuously differentiable.
 By basic calculus,
 either the minimum (or point achieving the minimum) is unbounded or the gradient is zero at a minimum.
 So we try to find a point with gradient close to zero (which,
 of course,
 does not guarantee global optimality).
 The basic algorithm is the following.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithm2e}[H]
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
caption{
\end_layout

\end_inset


\begin_inset Formula $\mathtt{GradientDescent}$
\end_inset

 (GD)
\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
SetAlgoLined
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
Input:

\series default
 Initial point 
\begin_inset Formula $x^{(0)}\in\Rn$
\end_inset

,
 step size 
\begin_inset Formula $h>0$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
For{
\end_layout

\end_inset


\begin_inset Formula $k=0,1,\cdots$
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}{
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lIf{
\end_layout

\end_inset


\begin_inset Formula $\|\nabla f(x^{(k)})\|_{2}\leq\epsilon$
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}{
\backslash
Return
\end_layout

\end_inset


\begin_inset Formula $x^{(k)}$
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
tcp{
\end_layout

\end_inset

Alternatively,
 one can use 
\begin_inset Formula $x^{(k+1)}\leftarrow\text{argmin}_{x=x^{(k)}+t\nabla f(x^{(k)}),t\in\R}f(x)$
\end_inset

.
\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $x^{(k+1)}\leftarrow x^{(k)}-h\cdot\nabla f(x^{(k)})$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{algorithm2e}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
One can view gradient descent as a greedy method for solving 
\begin_inset Formula $\min_{x\in\Rn}f(x)$
\end_inset

.
 At a point 
\begin_inset Formula $x$
\end_inset

,
 gradient descent goes to the minimizer of 
\begin_inset Formula 
\[
\min_{\|\delta\|_{2}\leq h\norm{\nabla f(x)}_{2}}f(x)+\nabla f(x)^{\top}\delta.
\]

\end_inset

The term 
\begin_inset Formula $f(x)+\nabla f(x)^{\top}\delta$
\end_inset

 is simply the first-order approximation of 
\begin_inset Formula $f(x+\delta)$
\end_inset

.
 Note that in this problem,
 the current point 
\begin_inset Formula $x$
\end_inset

 is fixed and we are optimizing the step 
\begin_inset Formula $\delta$
\end_inset

.
 Certainly,
 there is no inherent reason for using first-order approximation and the Euclidean norm 
\begin_inset Formula $\|x\|_{2}$
\end_inset

.
 For example,
 if you use second-order approximation,
 then you would get a method involving Hessian of 
\begin_inset Formula $f$
\end_inset

.
\end_layout

\begin_layout Standard
The step size of the algorithm usually either uses a fixed constant,
 or follows a predetermined schedule,
 or determined using a line search.
\end_layout

\begin_layout Standard
If the iteration stops,
 we get a point with 
\begin_inset Formula $\norm{\nabla f(x)}_{2}\le\epsilon$
\end_inset

.
 Why is this good?
 The hope is that 
\begin_inset Formula $x$
\end_inset

 is a near-minimum in the neighborhood of 
\begin_inset Formula $x$
\end_inset

.
 However,
 this might not be true if the gradient can fluctuate wildly:
\end_layout

\begin_layout Definition
We say 
\begin_inset Formula $f$
\end_inset

 has 
\begin_inset Formula $L$
\end_inset

-Lipschitz gradient if 
\begin_inset Formula $\nabla f$
\end_inset

 is 
\begin_inset Formula $L$
\end_inset

-Lipschitz,
 namely,
 
\begin_inset Formula $\|\nabla f(x)-\nabla f(y)\|_{2}\leq L\|x-y\|_{2}$
\end_inset

 for all 
\begin_inset Formula $x,y\in\R^{n}$
\end_inset

.
\end_layout

\begin_layout Definition
Similar to Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:equ_convex"
nolink "false"

\end_inset

,
 we have the following equivalence.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:L_equ_def"

\end_inset

Let 
\begin_inset Formula $f\in\mathcal{C}^{2}(\Rn)$
\end_inset

.
 For any 
\begin_inset Formula $L\geq0$
\end_inset

,
 the following are equivalent:
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset Formula $\|\nabla f(x)-\nabla f(y)\|_{2}\leq L\|x-y\|_{2}$
\end_inset

 for all 
\begin_inset Formula $x,y\in\Rn$
\end_inset

.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $-LI\preceq\nabla^{2}f(x)\preceq L$
\end_inset

I for all 
\begin_inset Formula $x\in\Rn$
\end_inset

.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\left|f(y)-f(x)-\nabla f(x)^{\top}(y-x)\right|\le\frac{L}{2}\|y-x\|_{2}^{2}$
\end_inset

 for all 
\begin_inset Formula $x,y\in\Rn$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Proof
\begin_inset Note Note
status open

\begin_layout Plain Layout
Somehow I need 4 proofs.
 Feel free to give more direct proof.
\end_layout

\end_inset

Suppose (1) holds.
 By the definition of 
\begin_inset Formula $\nabla^{2}f$
\end_inset

,
 we have
\begin_inset Formula 
\[
\nabla^{2}f(x)v=\lim_{h\rightarrow0}\frac{\nabla f(x+hv)-\nabla f(x)}{h}.
\]

\end_inset

Since 
\begin_inset Formula $\|\frac{\nabla f(x+hv)-\nabla f(x)}{h}\|_{2}\leq\frac{L}{h}\|hv\|_{2}=L\|v\|_{2}$
\end_inset

,
 we have 
\begin_inset Formula $\|\nabla^{2}f(x)v\|_{2}\leq L\|v\|_{2}$
\end_inset

,
 which means all eigenvalues of 
\begin_inset Formula $\nabla^{2}f$
\end_inset

 are at most 
\begin_inset Formula $L$
\end_inset

 in magnitude.
 This proves (2).
\end_layout

\begin_layout Proof
Suppose (2) holds.
 Since by the fundamental theorem of calculus,
 
\begin_inset Formula 
\[
\nabla f(x)-\nabla f(y)=\int_{0}^{1}\nabla^{2}f(y+t(x-y))(x-y)dt,
\]

\end_inset

we have that
\begin_inset Formula 
\[
\|\nabla f(x)-\nabla f(y)\|_{2}\leq\int_{0}^{1}\|\nabla^{2}f(y+t(x-y))\|_{\op}\|x-y\|_{2}dt\leq L\|x-y\|_{2}.
\]

\end_inset

This gives (1).
\end_layout

\begin_layout Proof
Suppose (2) holds.
 By integration along the direction 
\begin_inset Formula $y-x$
\end_inset

 from 
\begin_inset Formula $x$
\end_inset

 to 
\begin_inset Formula $y$
\end_inset

,
 we have
\begin_inset Formula 
\[
f(y)=f(x)+\nabla f(x)^{\top}(y-x)+\int_{0}^{1}(1-t)(y-x)^{\top}\nabla^{2}f(x+t(y-x))(y-x)dt.
\]

\end_inset

Since 
\begin_inset Formula $-LI\preceq\nabla^{2}f(x)\preceq LI$
\end_inset

,
 we have
\begin_inset Formula 
\[
\left|(y-x)^{\top}\nabla^{2}f(x+t(y-x))(y-x)\right|\le L\|y-x\|_{2}^{2}.
\]

\end_inset

This gives (3).
\end_layout

\begin_layout Proof
Suppose (3) holds,
 then 
\begin_inset Formula $g(x)=f(x)+\frac{L}{2}\|x\|_{2}^{2}$
\end_inset

 satisfies 
\begin_inset Formula $g(y)\geq g(x)+\nabla g(x)^{\top}(y-x)$
\end_inset

 for all 
\begin_inset Formula $x,y\in\Rn$
\end_inset

.
 So Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:equ_convex"
nolink "false"

\end_inset

 shows that 
\begin_inset Formula $g$
\end_inset

 is convex and 
\begin_inset Formula $\nabla^{2}g(x)\succeq0$
\end_inset

.
 Hence,
 
\begin_inset Formula $\nabla^{2}f(x)\succeq-LI$
\end_inset

.
 Similarly,
 by taking 
\begin_inset Formula $g(x)=\frac{L}{2}\|x\|_{2}^{2}-f(x)$
\end_inset

,
 we have 
\begin_inset Formula $\nabla^{2}f(x)\preceq LI$
\end_inset

.
 This gives (2).
\end_layout

\begin_layout Exercise
Prove the implication above (2) 
\begin_inset Formula $\Rightarrow$
\end_inset

 (3) by defining a one-dimensional function.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Exercise
Prove that if 
\begin_inset Formula $f\in{\cal C}^{2}(\R^{n})$
\end_inset

 has an 
\begin_inset Formula $L$
\end_inset

-Lipschitz gradient then the function 
\begin_inset Formula $g(x)=\frac{L}{2}\norm x_{2}^{2}-f(x)$
\end_inset

 satisfies 
\begin_inset Formula $\langle\nabla g(x)-\nabla g(y),x-y\rangle\ge0$
\end_inset

,
 and so 
\begin_inset Formula $g$
\end_inset

 is convex.
\end_layout

\begin_layout Standard
With the equivalent definitions in Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:L_equ_def"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 we can have an alternative view of gradient descent.
 Each step,
 we perform
\begin_inset Formula 
\[
x^{(k+1)}=\arg\min_{y}f(x^{(k)})+\left\langle \nabla f(x^{(k)}),y-x^{(k)}\right\rangle +\frac{L}{2}\|y-x^{(k)}\|_{2}^{2}.
\]

\end_inset

To see this is the same step,
 we let 
\begin_inset Formula 
\[
g(y)=f(x^{(k)})+\left\langle \nabla f(x^{(k)}),y-x^{(k)}\right\rangle +\frac{L}{2}\|y-x^{(k)}\|_{2}^{2}.
\]

\end_inset

The optimality condition shows that 
\begin_inset Formula $0=\nabla g(x^{(k+1)})=\nabla f(x^{(k)})+L(x^{(k+1)}-x^{(k)})$
\end_inset

.
 Hence,
 this gives the step 
\begin_inset Formula $x^{(k+1)}=x^{(k)}-\frac{1}{L}\nabla f(x^{(k)})$
\end_inset

.
\end_layout

\begin_layout Standard
By Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:L_equ_def"
nolink "false"

\end_inset

,
 we know that 
\begin_inset Formula $g$
\end_inset

 is an upper bound of 
\begin_inset Formula $f$
\end_inset

,
 namely 
\begin_inset Formula $g(y)\geq f(y)$
\end_inset

 for all 
\begin_inset Formula $y$
\end_inset

.
 In general,
 many optimization methods involves minimizing some upper bound function every step.
 Note that the progress we made for 
\begin_inset Formula $f$
\end_inset

 is at least the progress we made for 
\begin_inset Formula $g$
\end_inset

.
 If 
\begin_inset Formula $g$
\end_inset

 is exactly 
\begin_inset Formula $f$
\end_inset

,
 we can get all the progress we can make in one step.
 Hence,
 we should believe if 
\begin_inset Formula $g$
\end_inset

 is a better approximation of 
\begin_inset Formula $f$
\end_inset

,
 then we are making more progress.
 For gradient descent,
 it uses the simplest first-order approximation.
 Although this is not the best approximation one can come up with,
 it is robust enough to use in all sorts of applications.
\end_layout

\begin_layout Exercise
Show that any continuous convex function is Lipschitz over any compact subset of its domain.
\end_layout

\begin_layout Subsection
Analysis for general functions
\end_layout

\begin_layout Standard
Gradient descent works for both convex and non-convex functions.
 For non-convex function,
 we can only find a point with small gradient (called an 
\emph on
approximate stationary
\emph default
 point).
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:gd_general"

\end_inset

Let 
\begin_inset Formula $f\in\mathcal{C}^{2}(\R^{n})$
\end_inset

 with 
\begin_inset Formula $L$
\end_inset

-Lipschitz gradient and 
\begin_inset Formula $x^{*}$
\end_inset

 be any minimizer of 
\begin_inset Formula $f$
\end_inset

.
 Then 
\begin_inset Formula $\mathtt{GradientDescent}$
\end_inset

 with step size 
\begin_inset Formula $h=\frac{1}{L}$
\end_inset

 outputs a point 
\begin_inset Formula $x$
\end_inset

 such that 
\begin_inset Formula $\|\nabla f(x)\|_{2}\leq\epsilon$
\end_inset

 in at most 
\begin_inset Formula $\frac{2L}{\epsilon^{2}}\left(f(x^{(0)})-f(x^{*})\right)$
\end_inset

 iterations.
\end_layout

\begin_layout Standard
One practical advantage of line search is that the algorithm does not need to know a bound on the Lipschitz constant of the gradient.
 The next lemma shows that the function value must decrease along the GD path for a sufficiently small step size,
 and the magnitude of the decrease depends on the norm of the current gradient.
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lem:gradient_progress"

\end_inset

For any 
\begin_inset Formula $f\in\mathcal{C}^{2}(\R^{n})$
\end_inset

 with 
\begin_inset Formula $L$
\end_inset

-Lipschitz gradient,
 we have
\begin_inset Formula 
\[
f(x-\frac{1}{L}\nabla f(x))\leq f(x)-\frac{1}{2L}\|\nabla f(x)\|_{2}^{2}.
\]

\end_inset


\end_layout

\begin_layout Proof
Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:second_order"
nolink "false"

\end_inset

 shows that 
\begin_inset Formula 
\[
f(x-\frac{1}{L}\nabla f(x))=f(x)-\frac{1}{L}\|\nabla f(x)\|_{2}^{2}+\frac{1}{2L^{2}}\nabla f(x)^{\top}\nabla^{2}f(z)\nabla f(x)
\]

\end_inset

for some 
\begin_inset Formula $z\in[x,x-\frac{1}{L}\nabla f(x)]$
\end_inset

.
 Since 
\begin_inset Formula $\|\nabla^{2}f(x)\|_{\op}\leq L$
\end_inset

,
 we have that 
\begin_inset Formula 
\[
\nabla f(x)^{\top}\nabla^{2}f(z)\nabla f(x)\leq L\cdot\|\nabla f(x)\|_{2}^{2}.
\]

\end_inset

Putting this back above,
 we have 
\begin_inset Formula 
\[
f(x-\frac{1}{L}\nabla f(x))\le f(x)-\frac{1}{L}\|\nabla f(x)\|_{2}^{2}+\frac{L}{2L^{2}}\norm{\nabla f(x)}_{2}^{2}=f(x)-\frac{1}{2L}\|\nabla f(x)\|_{2}^{2}.
\]

\end_inset


\end_layout

\begin_layout Standard
We can now prove the theorem.
 
\end_layout

\begin_layout Proof
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Proof of Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_general"
nolink "false"

\end_inset


\end_layout

\end_inset

 We observe that either 
\begin_inset Formula $\|\nabla f(x)\|_{2}\le\epsilon$
\end_inset

,
 or 
\begin_inset Formula $\|\nabla f(x)\|_{2}\geq\epsilon$
\end_inset

 and so by Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:gradient_progress"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 the function value 
\begin_inset Formula $f(x)$
\end_inset

 decreases by at least 
\begin_inset Formula $\frac{\epsilon^{2}}{2L}$
\end_inset

.
 Since the function value can decrease by at most 
\begin_inset Formula $f(x^{(0)})-f(x^{*})$
\end_inset

,
 this bounds the number of iterations â€”
 each step of gradient descent decreases 
\begin_inset Formula $f$
\end_inset

 by at least 
\begin_inset Formula $\frac{\epsilon^{2}}{2L}$
\end_inset

 and since we can decrease 
\begin_inset Formula $f$
\end_inset

 by at most 
\begin_inset Formula $f(x^{(0)})-f(x^{*})$
\end_inset

,
 we have the result.
\end_layout

\begin_layout Standard
Despite the simplicity of the algorithm and the proof,
 it is known that this is the best one can do via any algorithm in this general setting 
\begin_inset CommandInset citation
LatexCommand cite
key "carmon2017lower"
literal "false"

\end_inset

.
\end_layout

\begin_layout Section
Analysis for convex functions
\end_layout

\begin_layout Standard
Assuming the function is convex,
 we can prove that gradient descent in fact converges to the global minimum.
 In particular,
 when 
\begin_inset Formula $\|\nabla f(x)\|_{2}$
\end_inset

 is small,
 convexity shows that 
\begin_inset Formula $f(x)-f(x^{*})$
\end_inset

 is small (Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:first_order"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lem:f_diff_diameter"

\end_inset

For any convex 
\begin_inset Formula $f\in\mathcal{C}^{1}(\Rn)$
\end_inset

,
 we have that 
\begin_inset Formula $f(x)-f(y)\leq\|\nabla f(x)\|_{2}\cdot\|x-y\|_{2}$
\end_inset

 for all 
\begin_inset Formula $x,y$
\end_inset

.
\end_layout

\begin_layout Proof
Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:first_order"
nolink "false"

\end_inset

 and Cauchy-Schwarz inequality shows that 
\begin_inset Formula 
\[
f(x)-f(y)\leq\left\langle \nabla f(x),x-y\right\rangle \leq\|\nabla f(x)\|_{2}\cdot\|x-y\|_{2}.
\]

\end_inset


\end_layout

\begin_layout Standard
This in turn give a better bound on the number of iterations because the bound in Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_general"
nolink "false"

\end_inset

 is affected by 
\begin_inset Formula $f(x)-f(x^{*})$
\end_inset

 rather than 
\begin_inset Formula $\norm{x-x^{*}}_{2}$
\end_inset


\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:gd_convex"

\end_inset

Let 
\begin_inset Formula $f\in\mathcal{C}^{2}(\R^{n})$
\end_inset

 be convex with 
\begin_inset Formula $L$
\end_inset

-Lipschitz gradient and 
\begin_inset Formula $x^{*}$
\end_inset

 be any minimizer of 
\begin_inset Formula $f$
\end_inset

.
 With step size 
\begin_inset Formula $h=\frac{1}{L}$
\end_inset

,
 the sequence 
\begin_inset Formula $x^{(k)}$
\end_inset

 in 
\begin_inset Formula $\mathtt{GradientDescent}$
\end_inset

 satisfies
\begin_inset Formula 
\[
f(x^{(k)})-f(x^{*})\leq\frac{2LR^{2}}{k+4}\text{ where }R=\max_{f(x)\leq f(x^{(0)})}\|x-x^{*}\|_{2}.
\]

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $\epsilon_{k}=f(x^{(k)})-f(x^{*})$
\end_inset

.
 Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:gradient_progress"
nolink "false"

\end_inset

 shows that
\begin_inset Formula 
\[
f(x^{(k+1)})=f(x^{(k)}-\frac{1}{L}\nabla f(x^{(k)}))\leq f(x^{(k)})-\frac{1}{2L}\|\nabla f(x^{(k)})\|_{2}^{2}.
\]

\end_inset

Subtracting 
\begin_inset Formula $f(x^{*})$
\end_inset

 from both sides,
 we have 
\begin_inset Formula $\epsilon_{k+1}\leq\epsilon_{k}-\frac{1}{2L}\|\nabla f(x^{(k)})\|_{2}^{2}$
\end_inset

.
 Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:f_diff_diameter"
nolink "false"

\end_inset

 shows that 
\begin_inset Formula 
\[
\epsilon_{k}\leq\|\nabla f(x^{(k)})\|_{2}\cdot\|x^{(k)}-x^{*}\|_{2}\leq\|\nabla f(x^{(k)})\|_{2}\cdot R.
\]

\end_inset

Therefore,
 we have that
\begin_inset Formula 
\[
\epsilon_{k+1}\leq\epsilon_{k}-\frac{1}{2L}\left(\frac{\epsilon_{k}}{R}\right)^{2}.
\]

\end_inset

Now,
 we need to solve the recursion.
 We note that
\begin_inset Formula 
\[
\frac{1}{\epsilon_{k+1}}-\frac{1}{\epsilon_{k}}=\frac{\epsilon_{k}-\epsilon_{k+1}}{\epsilon_{k}\epsilon_{k+1}}\geq\frac{\epsilon_{k}-\epsilon_{k+1}}{\epsilon_{k}^{2}}\geq\frac{1}{2LR^{2}}.
\]

\end_inset

Also,
 by Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:L_equ_def"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 we have that 
\begin_inset Formula 
\[
\epsilon_{0}=f(x^{(0)})-f(x^{*})\leq\nabla f(x^{*})^{\top}(x^{(0)}-x^{*})+\frac{L}{2}\|x^{(0)}-x^{*}\|_{2}^{2}\leq\frac{LR^{2}}{2}.
\]

\end_inset

Therefore,
 after 
\begin_inset Formula $k$
\end_inset

 iterations,
 we have
\begin_inset Formula 
\[
\frac{1}{\epsilon_{k}}\geq\frac{1}{\epsilon_{0}}+\frac{k}{2LR^{2}}\geq\frac{2}{LR^{2}}+\frac{k}{2LR^{2}}=\frac{k+4}{2LR^{2}}.
\]

\end_inset


\end_layout

\begin_layout Standard
This style of proof is typical in optimization.
 It shows that when the gradient is large,
 we make large progress and when the gradient is small,
 we are close to optimal.
 
\end_layout

\begin_layout Standard
This proof above does not make essential use any property of 
\begin_inset Formula $\ell_{2}$
\end_inset

 or inner product space.
 It can be extended to work for general norms if the gradient descent step is defined using that norm.
 For the case of 
\begin_inset Formula $\ell_{2}$
\end_inset

,
 one can prove that 
\begin_inset Formula $\|x^{(k)}-x^{*}\|_{2}$
\end_inset

 is in fact decreasing.
 
\end_layout

\begin_layout Lemma
For 
\begin_inset Formula $h\leq\frac{2}{L}$
\end_inset

,
 we have that 
\begin_inset Formula $\|x^{(k+1)}-x^{*}\|_{2}\leq\|x^{(k)}-x^{*}\|_{2}$
\end_inset

.
 Therefore,
 for an 
\begin_inset Formula $L$
\end_inset

-gradient Lipschitz convex function 
\begin_inset Formula $f$
\end_inset

,
 for GD with 
\begin_inset Formula $h=\frac{1}{L}$
\end_inset

,
 we have
\begin_inset Formula 
\[
f(x^{(k)})-f(x^{*})\leq\frac{2L\|x^{(0)}-x^{*}\|_{2}^{2}}{k+4}.
\]

\end_inset


\end_layout

\begin_layout Proof
We compute the distance to an optimal point as follows,
 noting that 
\begin_inset Formula $\nabla f(x^{*})=0$
\end_inset

:
\begin_inset Formula 
\begin{align*}
\|x^{(k+1)}-x^{*}\|_{2}^{2} & =\|x^{(k)}-x^{*}-h\nabla f(x^{(k)})\|_{2}^{2}\\
 & =\|x^{(k)}-x^{*}\|_{2}^{2}-2h\left\langle \nabla f(x^{(k)}),x^{(k)}-x^{*}\right\rangle +h^{2}\|\nabla f(x^{(k)})\|_{2}^{2}\\
 & =\|x^{(k)}-x^{*}\|_{2}^{2}-2h\left\langle \nabla f(x^{(k)})-\nabla f(x^{*}),x^{(k)}-x^{*}\right\rangle +h^{2}\|\nabla f(x^{(k)})-\nabla f(x^{*})\|_{2}^{2}.
\end{align*}

\end_inset

To handle the term 
\begin_inset Formula $\nabla f(x)-\nabla f(x^{*})$
\end_inset

,
 we note that
\begin_inset Formula 
\[
\nabla f(x^{(k)})-\nabla f(x^{*})=H(x^{(k)}-x^{*})
\]

\end_inset

with 
\begin_inset Formula $H=\int_{0}^{1}\nabla^{2}f(x^{*}+t(x^{(k)}-x^{*}))dt$
\end_inset

.
 Since 
\begin_inset Formula $0\preceq H\preceq LI$
\end_inset

 and that 
\begin_inset Formula $H\succeq\frac{1}{L}H^{2}$
\end_inset

,
 we have
\begin_inset Formula 
\begin{align*}
\left\langle \nabla f(x^{(k)})-\nabla f(x^{*}),x^{(k)}-x^{*}\right\rangle  & =(x^{(k)}-x^{*})^{\top}H(x^{(k)}-x^{*})\\
 & \geq\frac{1}{L}(x^{(k)}-x^{*})^{\top}H^{2}(x^{(k)}-x^{*})\\
 & =\frac{1}{L}\|\nabla f(x^{(k)})-\nabla f(x^{*})\|_{2}^{2}.
\end{align*}

\end_inset

Hence,
 we have
\begin_inset Formula 
\begin{align*}
\|x^{(k+1)}-x^{*}\|_{2}^{2} & \leq\|x^{(k)}-x^{*}\|_{2}^{2}-(\frac{2h}{L}-h^{2})\|\nabla f(x^{(k)})-\nabla f(x^{*})\|_{2}^{2}\\
 & \leq\|x^{(k)}-x^{*}\|_{2}^{2}.
\end{align*}

\end_inset

The error estimate follows from 
\begin_inset Formula $\|x^{(k)}-x^{*}\|_{2}^{2}\leq\|x^{(0)}-x^{*}\|_{2}^{2}$
\end_inset

 for all 
\begin_inset Formula $k$
\end_inset

 and the proof in Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_convex"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Exercise
Show for GD on convex,
 
\begin_inset Formula $L$
\end_inset

-gradient Lipschitz 
\begin_inset Formula $f\in\mathcal{C}^{2}(\R^{n})$
\end_inset

 with step size 
\begin_inset Formula $h\leq\frac{1}{L}$
\end_inset

,
 the sequence 
\begin_inset Formula $x^{(k)}$
\end_inset

 satisfies 
\begin_inset Formula $||\nabla f(x^{(k+1)})||_{2}\leq||\nabla f(x^{(k)})||_{2}$
\end_inset

 for all 
\begin_inset Formula $k$
\end_inset

.
 
\end_layout

\begin_layout Standard
Rewriting the bound,
 Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_convex"
nolink "false"

\end_inset

 shows it takes 
\begin_inset Formula $\frac{2L\|x^{(0)}-x^{*}\|_{2}^{2}}{\epsilon}$
\end_inset

 iterations.
 Compare to the bound 
\begin_inset Formula $\frac{2L}{\epsilon^{2}}\left(f(x^{(0)})-f(x^{*})\right)$
\end_inset

 in Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_general"
nolink "false"

\end_inset

,
 it seems the new result has a strictly better dependence on 
\begin_inset Formula $\epsilon$
\end_inset

.
 However,
 this is not true because one measures the error in terms of 
\begin_inset Formula $\|\nabla f(x)\|_{2}$
\end_inset

 while the other is in terms of 
\begin_inset Formula $f(x)-f(x^{*})$
\end_inset

.
 For 
\begin_inset Formula $f(x)=x^{2}/2$
\end_inset

,
 we have 
\begin_inset Formula $f(x)-f(x^{*})=\|\nabla f(x)\|_{2}^{2}$
\end_inset

 and hence both have the same dependence on 
\begin_inset Formula $\epsilon$
\end_inset

 for this particular function.
 So,
 the real benefit of Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_convex"
nolink "false"

\end_inset

 is its global convergence.
\end_layout

\begin_layout Section
Strongly Convex Functions
\end_layout

\begin_layout Standard
We note that the convergence rate 
\begin_inset Formula $\epsilon^{-1}$
\end_inset

 or 
\begin_inset Formula $\epsilon^{-2}$
\end_inset

 is not great if we need to solve the problem up to very high accuracy (e.g.,
 up to 
\begin_inset Formula $n$
\end_inset

 bits would mean 
\begin_inset Formula $\epsilon=2^{-n}$
\end_inset

).
 Getting to very high accuracy is sometimes important if the optimization problem is used as a subroutine.
 We note that for the case 
\begin_inset Formula $f(x)=\frac{1}{2}\|x\|_{2}^{2}$
\end_inset

,
 gradient descent with step size 
\begin_inset Formula $h=1$
\end_inset

 takes exactly 
\begin_inset Formula $1$
\end_inset

 step.
 Therefore,
 it is natural to ask if one can improve the bound for functions close to quadratics.
 This motivates the following assumption.
\end_layout

\begin_layout Definition
We say a function 
\begin_inset Formula $f\in\mathcal{C}^{1}(\Rn)$
\end_inset

 is 
\begin_inset Formula $\mu$
\end_inset

-strongly convex if for any 
\begin_inset Formula $x,y\in\Rn$
\end_inset

 
\begin_inset Formula 
\[
f(y)\geq f(x)+\nabla f(x)^{\top}(y-x)+\frac{\mu}{2}\|y-x\|_{2}^{2}.
\]

\end_inset


\end_layout

\begin_layout Standard
A 
\begin_inset Quotes eld
\end_inset

growth
\begin_inset Quotes erd
\end_inset

 of a strongly convex function around any point is lower bounded by a quadratic function.
 Clearly a strongly convex function is also convex and the sum of a strongly convex and convex function remains strongly convex.
 An example of a function that is convex but not strongly convex is 
\begin_inset Formula $f(x)=\left|x\right|$
\end_inset

.
 Similar to the convex case (Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:equ_convex"
nolink "false"

\end_inset

),
 we have the following.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $f\in\mathcal{C}^{2}(\Rn)$
\end_inset

.
 For any 
\begin_inset Formula $\mu\geq0$
\end_inset

,
 the following are equivalent:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $f(tx+(1-t)y)\leq tf(x)+(1-t)f(y)-\frac{1}{2}\mu t(1-t)\|x-y\|_{2}^{2}$
\end_inset

 for all 
\begin_inset Formula $x,y\in\Rn$
\end_inset

 and 
\begin_inset Formula $t\in[0,1]$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $f(y)\geq f(x)+\nabla f(x)^{\top}(y-x)+\frac{\mu}{2}\|y-x\|_{2}^{2}$
\end_inset

 for all 
\begin_inset Formula $x,y\in\Rn$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $\nabla^{2}f(x)\succeq\mu$
\end_inset

I for all 
\begin_inset Formula $x\in\Rn$
\end_inset


\end_layout

\end_deeper
\begin_layout Proof
It follows from applying Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:equ_convex"
nolink "false"

\end_inset

 on the function 
\begin_inset Formula $g(x)=f(x)-\frac{\mu}{2}\|x\|_{2}^{2}$
\end_inset

.
\end_layout

\begin_layout Standard
Next,
 we study gradient descent for 
\begin_inset Formula $\mu$
\end_inset

-strongly convex functions.
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lem:strongly_convex"

\end_inset

Let 
\begin_inset Formula $f\in\mathcal{C}^{2}(\R^{n})$
\end_inset

 be 
\begin_inset Formula $\mu$
\end_inset

-strongly convex.
 Then,
 for any 
\begin_inset Formula $x,y\in\R^{n},$
\end_inset

we have
\begin_inset Formula 
\[
\norm{\nabla f(x)}_{2}^{2}\ge2\mu\left(f(x)-f(y)\right).
\]

\end_inset


\end_layout

\begin_layout Proof
By the definition of 
\begin_inset Formula $\mu$
\end_inset

 strong convexity,
 we have 
\begin_inset Formula 
\[
f(y)\ge f(x)+\langle\nabla f(x),y-x\rangle+\frac{\mu}{2}\norm{x-y}_{2}^{2}.
\]

\end_inset


\end_layout

\begin_layout Proof
Rearranging,
 we have 
\begin_inset Formula 
\[
f(x)-f(y)\le\langle\nabla f(x),x-y\rangle-\frac{\mu}{2}\norm{x-y}_{2}^{2}\le\max_{\Delta}\nabla f(x)^{\top}\Delta-\frac{\mu}{2}\norm{\Delta}_{2}^{2}=\frac{1}{2\mu}\norm{\nabla f(x)}_{2}^{2}.
\]

\end_inset


\end_layout

\begin_layout Standard
This will lead to the following guarantee.
 Note that the error now decreases geometrically rather than additively.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:gd_convex_strongly"

\end_inset

Let 
\begin_inset Formula $f\in\mathcal{C}^{2}(\R^{n})$
\end_inset

 be 
\begin_inset Formula $\mu$
\end_inset

-strongly convex with 
\begin_inset Formula $L$
\end_inset

-Lipschitz gradient and 
\begin_inset Formula $x^{*}$
\end_inset

 be any minimizer of 
\begin_inset Formula $f$
\end_inset

.
 With step size 
\begin_inset Formula $h=\frac{1}{L}$
\end_inset

,
 the sequence 
\begin_inset Formula $x^{(k)}$
\end_inset

 in 
\begin_inset Formula $\mathtt{GradientDescent}$
\end_inset

 satisfies
\begin_inset Formula 
\[
f(x^{(k)})-f(x^{*})\leq\left(1-\frac{\mu}{L}\right){}^{k}\left(f(x^{(0)})-f(x^{*})\right).
\]

\end_inset


\end_layout

\begin_layout Standard
In a later chapter,
 we will see that an 
\emph on
accelerated 
\emph default
variant of gradient descent improves this further by replacing the 
\begin_inset Formula $\frac{\mu}{L}$
\end_inset

 term with 
\begin_inset Formula $\sqrt{\frac{\mu}{L}}$
\end_inset

.
\end_layout

\begin_layout Proof
Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:gradient_progress"
nolink "false"

\end_inset

 shows that
\begin_inset Formula 
\begin{align}
f(x^{(k+1)})-f(x^{*}) & \leq f(x^{(k)})-f(x^{*})-\frac{1}{2L}\|\nabla f(x^{(k)})\|_{2}^{2}\label{eq:strong_convex_progress}\\
 & \le f(x^{(k)})-f(x^{*})-\frac{\mu}{L}\left(f(x^{(k)})-f^{*}\right)\\
 & =\left(1-\frac{\mu}{L}\right)\left(f(x^{(k)})-f^{*}\right)
\end{align}

\end_inset

where we used Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:strongly_convex"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 The conclusion follows.
\end_layout

\begin_layout Standard
A similar bound also holds for convergence to the optimal point.
 
\end_layout

\begin_layout Exercise
Let 
\begin_inset Formula $f\in\mathcal{C}^{2}(\R^{n})$
\end_inset

 be 
\begin_inset Formula $\mu$
\end_inset

-strongly convex with 
\begin_inset Formula $L$
\end_inset

-Lipschitz gradient and 
\begin_inset Formula $x^{*}$
\end_inset

 be the minimizer of 
\begin_inset Formula $f$
\end_inset

.
 With step size 
\begin_inset Formula $h=1/L$
\end_inset

,
 show that the sequence 
\begin_inset Formula $x^{(k)}$
\end_inset

 in 
\begin_inset Formula $\mathtt{GradientDescent}$
\end_inset

 satisfies 
\begin_inset Formula 
\[
\|x^{(k)}-x^{*}\|_{2}^{2}\le\left(1-\frac{\mu}{L}\right)^{k}\left\Vert x^{(0)}-x^{*}\right\Vert _{2}^{2}.
\]

\end_inset


\end_layout

\begin_layout Standard
It is natural to ask to what extent the assumption of convexity is essential for the bounds we obtained.
 This is the motivation for the next exercises.
\end_layout

\begin_layout Exercise
Suppose 
\begin_inset Formula $f$
\end_inset

 satisfies 
\begin_inset Formula $\left\langle \nabla f(x),x-x^{*}\right\rangle \ge\alpha\left(f(x)-f(x^{*})\right)$
\end_inset

.
 Derive a bound similar to Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_convex"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 for gradient descent.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Exercise
Suppose 
\begin_inset Formula $f$
\end_inset

 satisfies 
\begin_inset Formula $\norm{\nabla f(x)}_{2}^{2}\ge2\mu\left(f(x)-f(x^{*})\right).$
\end_inset

 Derive a bound similar to Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_convex_strongly"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 for gradient descent.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Exercise
For each of the above conditions,
 give an example of a nonconvex function that satisfies it.
 (Note:
 convex functions satisfy the first with 
\begin_inset Formula $\alpha=1$
\end_inset

 and 
\begin_inset Formula $\mu$
\end_inset

-strongly convex functions satisfy the second.)
\end_layout

\begin_layout Section
Line Search
\end_layout

\begin_layout Standard
In practice,
 we often stop line search early because we can make larger progress in a new direction.
 A standard stopping condition is called the Wolfe condition.
\end_layout

\begin_layout Definition
A step size 
\begin_inset Formula $h$
\end_inset

 satisfies the Wolfe condition with respect to direction 
\begin_inset Formula $p$
\end_inset

 if
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset Formula $f(x+hp)\leq f(x)+c_{1}h\cdot p^{\top}\nabla f(x)$
\end_inset

,
\end_layout

\begin_layout Enumerate
\begin_inset Formula $-p^{\top}\nabla f(x+hp)\leq-c_{2}p^{\top}\nabla f(x)$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Definition
with 
\begin_inset Formula $0<c_{1}<c_{2}<1$
\end_inset

.
\end_layout

\begin_layout Standard
Let the objective for progress be 
\begin_inset Formula $\phi(h)=f(x)-f(x+hp)$
\end_inset

.
 The first condition requires the algorithm makes sufficient progress (
\begin_inset Formula $\phi(h)\geq c_{1}h\cdot\phi'(0)$
\end_inset

).
 The second condition requires the slope to reduce significantly (
\begin_inset Formula $\phi'(h)\leq c_{2}\phi'(0)$
\end_inset

).
 One can think the first condition gives a upper bound on 
\begin_inset Formula $h$
\end_inset

 while the second condition gives a lower bound on 
\begin_inset Formula $h$
\end_inset

.
 In general,
 a step size satisfying the Wolfe conditions will be larger than the step size 
\begin_inset Formula $h=\frac{1}{L}$
\end_inset

.
 In particular,
 one can show the following.
\end_layout

\begin_layout Exercise
Suppose 
\begin_inset Formula $f$
\end_inset

 is 
\begin_inset Formula $\mu$
\end_inset

-strongly convex and has 
\begin_inset Formula $L$
\end_inset

-Lipschitz gradient.
 If a step size 
\begin_inset Formula $h$
\end_inset

 satisfies the Wolfe condition with respect to the direction 
\begin_inset Formula $p=-\nabla f(x)$
\end_inset

,
 then show that
\begin_inset Formula 
\[
\frac{2(1-c_{1})}{\mu}\geq h\geq\frac{1-c_{2}}{L}.
\]

\end_inset


\end_layout

\begin_layout Standard
As a corollary,
 we have that the function value progress given by such step is 
\begin_inset Formula $\Omega(\|\nabla f(x)\|^{2}/L)$
\end_inset

.
 Therefore,
 this gives the same guarantee Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_convex"
nolink "false"

\end_inset

 and Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_convex_strongly"
nolink "false"

\end_inset

.
 A common way to implement this is via a backtracking line search.
 The algorithm starts with a large step size and decreases it by a constant factor if the Wolfe conditions are violated.
 For gradient descent,
 the next step involves exactly computing 
\begin_inset Formula $\nabla f(x+hp)$
\end_inset

 and hence if our line search accepts the step size immediately,
 the line search almost costs nothing extra.
 Therefore,
 if we maintain a step size throughout the algorithm and decreases it only when it violates the condition,
 the total cost of the line search will be only an additive logarithmic number of gradient calls throughout the algorithm and is negligible.
\end_layout

\begin_layout Standard
Finally,
 we note that for problems of the form 
\begin_inset Formula $f(x)=\sum_{i}f_{i}(a_{i}^{\top}x)$
\end_inset

,
 the bottleneck is often in computing 
\begin_inset Formula $Ax$
\end_inset

.
 In this case,
 exact line search is almost free because we can store the vectors 
\begin_inset Formula $Ax$
\end_inset

 and 
\begin_inset Formula $Ah$
\end_inset

.
\end_layout

\begin_layout Section
Generalizing Gradient Descent*
\end_layout

\begin_layout Standard
Here we study properties of gradient descent that were actually used for the strongly convex case.
 There are many ways to generalize this case.
 One way is to view gradient descent is as approximating the function 
\begin_inset Formula $f$
\end_inset

 by splitting it into two terms,
 one is the first-order approximation and the second is just a squared 
\begin_inset Formula $\ell_{2}$
\end_inset

 norm.
 More generally,
 we can split a function into two terms,
 one that is easy to optimize and another that we need to approximate with some error.
 More precisely,
 we consider the following 
\end_layout

\begin_layout Definition
We say 
\begin_inset Formula $g+h$
\end_inset

 is an 
\begin_inset Formula $\alpha$
\end_inset

-approximation to 
\begin_inset Formula $f$
\end_inset

 at the point 
\begin_inset Formula $x$
\end_inset

 if
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $g$
\end_inset

 is convex,
 with the same value as 
\begin_inset Formula $f$
\end_inset

 at 
\begin_inset Formula $x$
\end_inset

,
 i.e.,
 
\begin_inset Formula $g(x)=f(x)$
\end_inset

 ,
\end_layout

\begin_layout Itemize
\begin_inset Formula $h(x)=0$
\end_inset

 and 
\begin_inset Formula $h((1-\alpha)x+\alpha\widehat{x})\leq\alpha^{2}h(\widehat{x})$
\end_inset

 for all 
\begin_inset Formula $\widehat{x}$
\end_inset

,
\end_layout

\begin_layout Itemize
\begin_inset Formula $g(y)+\alpha h(y)\leq f(y)\leq g(y)+h(y)\text{ for all }y.$
\end_inset

 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Sushant said the quadratic lower bound condition can be replaced by 
\end_layout

\begin_layout Plain Layout
\begin_inset Formula $g(y)+\alpha h(y/\alpha)\leq f(y)\leq g(y)+h(y)\text{ for all }$
\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
To understand this assumption,
 we note that if 
\begin_inset Formula $f$
\end_inset

 is 
\begin_inset Formula $\mu$
\end_inset

-strongly convex with 
\begin_inset Formula $L$
\end_inset

-Lipschitz gradient,
 then for any 
\begin_inset Formula $x$
\end_inset

,
 we can use 
\begin_inset Formula $\alpha=\frac{\mu}{L}$
\end_inset

 and
\begin_inset Formula 
\begin{align*}
g(y) & =f(x)+\left\langle \nabla f(x),y-x\right\rangle ,\\
h(y) & =\frac{L}{2}\|y-x\|^{2}.
\end{align*}

\end_inset

The condition requires 
\begin_inset Formula $h$
\end_inset

 converging to 
\begin_inset Formula $0$
\end_inset

 quadratically when 
\begin_inset Formula $y\rightarrow x$
\end_inset

.
 
\end_layout

\begin_layout Standard
Now,
 we consider the following algorithm:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithm2e}[H]
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
caption{
\end_layout

\end_inset


\begin_inset Formula $\mathtt{GeneralizedGradientDescent}$
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
SetAlgoLined
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
Input:

\series default
 Initial point 
\begin_inset Formula $x^{(0)}\in\Rn$
\end_inset

,
 approximation factor 
\begin_inset Formula $\alpha>0$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
For{
\end_layout

\end_inset


\begin_inset Formula $k=0,1,\cdots$
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}{
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Find an 
\begin_inset Formula $\alpha$
\end_inset

-approximation of 
\begin_inset Formula $f$
\end_inset

 at 
\begin_inset Formula $x^{(k)}$
\end_inset

 given by 
\begin_inset Formula $g^{(k)}(x)+h^{(k)}(x)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula $x^{(k+1)}\leftarrow\arg\min_{y}g^{(k)}(y)+h^{(k)}(y)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{algorithm2e}
\end_layout

\end_inset


\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:gd_general_apx"

\end_inset

 Suppose we are given a convex function 
\begin_inset Formula $f$
\end_inset

 such that we can find an 
\begin_inset Formula $\alpha$
\end_inset

-approximation at any 
\begin_inset Formula $x$
\end_inset

.
 Let 
\begin_inset Formula $x^{*}$
\end_inset

 be any minimizer of 
\begin_inset Formula $f$
\end_inset

.
 Then the sequence 
\begin_inset Formula $x^{(k)}$
\end_inset

 in 
\begin_inset Formula $\mathtt{GeneralizedGradientDescent}$
\end_inset

 satisfies
\begin_inset Formula 
\[
f(x^{(k)})-f(x^{*})\leq(1-\alpha)^{k}(f(x^{(0)})-f(x^{*})).
\]

\end_inset


\end_layout

\begin_layout Proof
Using the fact that 
\begin_inset Formula $g^{(k)}+h^{(k)}$
\end_inset

 is an upper bound on 
\begin_inset Formula $f$
\end_inset

,
 we have that our progress on 
\begin_inset Formula $f$
\end_inset

 is larger than the best possible progress on 
\begin_inset Formula $g^{(k)}+h^{(k)}$
\end_inset

:
\begin_inset Formula 
\[
f(x^{(k+1)})\leq\min_{y}g^{(k)}(y)+h^{(k)}(y).
\]

\end_inset

To bound the best possible progress,
 i.e.,
 the RHS above,
 we consider 
\begin_inset Formula $\widehat{x}=\arg\min_{y}g^{(k)}(y)+\alpha h^{(k)}(y)$
\end_inset

 and 
\begin_inset Formula $z=(1-\alpha)x^{(k)}+\alpha\widehat{x}$
\end_inset

.
 We have that
\begin_inset Formula 
\begin{align*}
\min_{y}g^{(k)}(y)+h^{(k)}(y) & \leq g^{(k)}(z)+h^{(k)}(z)\\
 & \leq(1-\alpha)g^{(k)}(x^{(k)})+\alpha g^{(k)}(\widehat{x})+\alpha^{2}h^{(k)}(\widehat{x})\\
 & \leq(1-\alpha)g^{(k)}(x^{(k)})+\alpha(g^{(k)}(x^{*})+\alpha h^{(k)}(x^{*}))
\end{align*}

\end_inset

where we used 
\begin_inset Formula $g^{(k)}$
\end_inset

 is convex and the assumption on 
\begin_inset Formula $h$
\end_inset

 in the second inequality,
 we used 
\begin_inset Formula $\widehat{x}$
\end_inset

 minimizes 
\begin_inset Formula $g^{(k)}+\alpha h^{(k)}$
\end_inset

.
\end_layout

\begin_layout Proof
Combining both and using the fact that 
\begin_inset Formula $g^{(k)}+\alpha h^{(k)}$
\end_inset

 is a lower bound on 
\begin_inset Formula $f$
\end_inset

,
 we have
\begin_inset Formula 
\[
f(x^{(k+1)})\leq(1-\alpha)f(x^{(k)})+\alpha f(x^{*}).
\]

\end_inset

This gives the result.
\end_layout

\begin_layout Standard
Although Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_general_apx"
nolink "false"

\end_inset

 looks weird,
 it captures many well-known theorems.
 Here we list some of them.
\end_layout

\begin_layout Exercise
Show that the third condition in the definition of 
\begin_inset Formula $\alpha$
\end_inset

-approximation can be replaced by 
\begin_inset Formula 
\[
g(y)+\alpha h(y/\alpha)\leq f(y)\leq g(y)+h(y)
\]

\end_inset

 while maintaining the guarantee for the convergence of generalized GD.
\end_layout

\begin_layout Subsubsection*
Projected Gradient Descent / Proximal Gradient Descent
\end_layout

\begin_layout Standard
Given a convex set 
\begin_inset Formula $K$
\end_inset

,
 a 
\begin_inset Formula $\mu$
\end_inset

-strongly convex function 
\begin_inset Formula $f$
\end_inset

 with 
\begin_inset Formula $L$
\end_inset

-Lipschitz gradient,
 we consider the problem
\begin_inset Formula 
\[
\min_{x\in K}f(x).
\]

\end_inset

To apply Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_general_apx"
nolink "false"

\end_inset

 to 
\begin_inset Formula $F(x)\defeq f(x)+\delta_{K}(x)$
\end_inset

,
 for any 
\begin_inset Formula $x$
\end_inset

,
 we consider the functions
\begin_inset Formula 
\begin{align*}
g(y) & =f(x)+\left\langle \nabla f(x),y-x\right\rangle +\delta_{K}(y),\\
h(y) & =\frac{L}{2}\|y-x\|_{2}^{2}.
\end{align*}

\end_inset

Note that 
\begin_inset Formula $g+h$
\end_inset

 is a 
\begin_inset Formula $\frac{\mu}{L}$
\end_inset

-approximation to 
\begin_inset Formula $F$
\end_inset

.
 Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_general_apx"
nolink "false"

\end_inset

 shows the 
\begin_inset Formula $\mathtt{GeneralizedGradientDescent}$
\end_inset

 converges in 
\begin_inset Formula $O(\frac{L}{\mu}\log(1/\epsilon))$
\end_inset

 steps where each step involves solving the problem
\begin_inset Formula 
\[
\min_{y\in K}f(x)+\left\langle \nabla f(x),y-x\right\rangle +\frac{L}{2}\|y-x\|_{2}^{2}.
\]

\end_inset


\end_layout

\begin_layout Standard
More generally,
 this works for problems of the form
\begin_inset Formula 
\[
\min_{x}f(x)+\phi(x)
\]

\end_inset

for some convex function 
\begin_inset Formula $\phi(x)$
\end_inset

.
 Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_general_apx"
nolink "false"

\end_inset

 requires us to solve a sub-problem of the form
\begin_inset Formula 
\[
\min_{y}f(x)+\left\langle \nabla f(x),y-x\right\rangle +\frac{L}{2}\|y-x\|_{2}^{2}+\phi(y).
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
\begin_inset Formula $\ell^{p}$
\end_inset

 Regression
\end_layout

\begin_layout Standard
One can apply this framework for optimizing 
\begin_inset Formula $\ell^{p}$
\end_inset

 regression 
\begin_inset Formula $\min_{x}\|Ax-b\|_{p}^{p}$
\end_inset

.
 For example,
 one can approximate the function 
\begin_inset Formula $f(x)=x^{p}$
\end_inset

 by 
\begin_inset Formula $g(y)=x^{p}+px^{p-1}(y-x)$
\end_inset

 and 
\begin_inset Formula $h(y)=p2^{p-1}(x^{p-2}(y-x)^{2}+(y-x)^{p})$
\end_inset

.
 Using this,
 one can show that one can solve the problem
\begin_inset Formula 
\[
\min_{x}\|Ax-b\|_{p}^{p}
\]

\end_inset

using the problem
\begin_inset Formula 
\begin{equation}
\min_{y}v^{\top}y+\|DA(y-x)\|_{2}^{2}+\|A(y-x)\|_{p}^{p}\label{eq:l2lp}
\end{equation}

\end_inset

for some vector 
\begin_inset Formula $v$
\end_inset

 and some diagonal matrix 
\begin_inset Formula $D$
\end_inset

.
 One can show that Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_general_apx"
nolink "false"

\end_inset

 only need to solve the sub-problem approximately.
 Therefore,
 this shows that one can solve 
\begin_inset Formula $\ell^{p}$
\end_inset

 regression with 
\begin_inset Formula $\log(1/\epsilon)$
\end_inset

 convergence by solving mixed 
\begin_inset Formula $\ell_{2}+\ell_{p}$
\end_inset

 regression approximately.
 
\end_layout

\begin_layout Subsubsection*
Other assumptions
\end_layout

\begin_layout Standard
For some special cases,
 it is possible to analyze this algorithm without convexity.
 One prominent application is compressive sensing:
 
\begin_inset Formula 
\[
\min_{\|x\|_{0}\leq k}\|Ax-b\|_{2}^{2}.
\]

\end_inset

For matrices 
\begin_inset Formula $A$
\end_inset

 satisfying restricted isometry property,
 one can apply 
\begin_inset Formula $\mathtt{GeneralizedGradientDescent}$
\end_inset

 to solve the problem with the splitting 
\begin_inset Formula $g(y)=\norm{Ax-b}_{2}^{2}+\langle2A^{\top}(Ax-b),y-x\rangle+\delta_{\|y\|_{0}\leq k}$
\end_inset

 and 
\begin_inset Formula $h(y)=\|y-x\|_{2}^{2}$
\end_inset

.
 In this case,
 the algorithm is called iterative hard-thresholding 
\begin_inset CommandInset citation
LatexCommand cite
key "blumensath2009iterative"
literal "false"

\end_inset

 and the sub-problem has a closed form expression.
\end_layout

\begin_layout Exercise
Give the closed form solution for the sub-problem given by the splitting above.
\end_layout

\begin_layout Section
Gradient Flow
\end_layout

\begin_layout Standard
In continuous time,
 gradient descent follows the Ordinary Differential Equation (ODE) 
\begin_inset Formula 
\[
\frac{dx_{t}}{dt}=-\nabla f(x_{t}).
\]

\end_inset

This can be viewed as the canonical continuous algorithm.
 Finding the right discretization has lead to many fruitful research directions.
 One benefit of the continuous view is to simplify some calculations.
 For example,
 for strongly convex 
\begin_inset Formula $f$
\end_inset

,
 Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_convex_strongly"
nolink "false"

\end_inset

 now becomes
\begin_inset Formula 
\[
\frac{d}{dt}(f(x_{t})-f(x^{*}))=\nabla f(x_{t})^{\top}\frac{dx_{t}}{dt}=-\|\nabla f(x_{t})\|_{2}^{2}\leq-2\mu\left(f(x_{t})-f(x^{*})\right)
\]

\end_inset

where we used Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:strongly_convex"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 at the end.
 Solving this differential inequality,
 we have
\begin_inset Formula 
\[
f(x_{t})-f(x^{*})\leq e^{-2\mu t}(f(x_{0})-f(x^{*})).
\]

\end_inset

Without the strong convexity assumption,
 gradient flow can behave wildly.
 For example,
 the length of the gradient flow can be exponential in 
\begin_inset Formula $d$
\end_inset

 on a unit ball 
\begin_inset CommandInset citation
LatexCommand cite
key "manselli1991maximum"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
We emphasize that this continuous view is mainly useful for understanding,
 indicative of but not necessarily implying an algorithmic result.
 In some cases,
 effective algorithmic results can be obtained simply by discretizing time in the gradient flow.
 The study of such numerical methods and their convergence properties is its own field,
 and well-known basic methods include the forward Euler method (which results in the basic version of GD),
 the 
\emph on
backward 
\emph default
Euler method,
 the Implicit Midpoint method and Runge-Kutta methods.
 We will see that gradient flow and its discretization also play an important role in the development of sampling algorithms.
\end_layout

\begin_layout Section
Discussion
\end_layout

\begin_layout Standard
Convex optimization by variants of gradient descent is a very active field with an increasing number of applications.
 Often,
 methods that are provable for the convex setting are applied as heuristics to nonconvex problems as well,
 most notably in deep learning.
 This is one of the principal features of GD,
 its wide applicability as an algorithmic paradigm.
 
\end_layout

\begin_layout Standard
Researchers are also using GD to get provably faster algorithms for classical problems.
 For example,
 
\begin_inset CommandInset citation
LatexCommand cite
key "adil2019iterative"
literal "false"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand cite
key "kyng2019flows"
literal "false"

\end_inset

 applied the decomposition of Eqn.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:l2lp"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 to obtain fast algorithms for 
\begin_inset Formula $\ell^{p}$
\end_inset

 regression and the 
\begin_inset Formula $\ell^{p}$
\end_inset

 flow problem.
 
\begin_inset CommandInset citation
LatexCommand cite
key "kathuria2020unit"
literal "false"

\end_inset

 showed that the 
\begin_inset Formula $\ell^{p}$
\end_inset

 flow problem can be used as a subroutine to solve uncapacitied maximum flow problem in 
\begin_inset Formula $m^{4/3+o(1)}$
\end_inset

 time.
 Instead of assuming 
\begin_inset Formula $h(x)$
\end_inset

 converges to 
\begin_inset Formula $0$
\end_inset

 quadratically,
 
\begin_inset CommandInset citation
LatexCommand cite
key "lu2016relatively"
literal "false"

\end_inset

 proved Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:gd_general_apx"
nolink "false"

\end_inset

 assuming 
\begin_inset Formula $h$
\end_inset

 is given by some divergence function and showed its applications in D-optimal design.
\end_layout

\end_body
\end_document
