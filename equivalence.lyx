#LyX 2.4 created this file. For more info see https://www.lyx.org/
\lyxformat 620
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass optbook
\use_default_options true
\maintain_unincluded_children no
\language english
\language_package default
\inputencoding auto-legacy
\fontencoding auto
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_roman_osf false
\font_sans_osf false
\font_typewriter_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement h
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_formatted_ref 0
\use_minted 0
\use_lineno 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tablestyle default
\tracking_changes false
\output_changes false
\change_bars false
\postpone_fragile_content false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\docbook_table_output 0
\docbook_mathml_prefix 1
\end_header

\begin_body

\begin_layout Standard
Reduction is a powerful paradigm in both algorithms and complexity.
 In algorithms,
 a dual view of a problem can sometimes provide a window to a more efficient algorithm.
 With this as the main motivation,
 we discuss the problem of convex optimization given different types of access to the instance at hand.
 Despite appearing to be rather different,
 all these perspectives will turn out to be equivalent,
 i.e.,
 reducible to each other,
 with only polynomial overhead.
 The main tool is duality.
 This chapter elaborates on these ideas.
 For the classical treatment of oracle models,
 the reader is referred to 
\begin_inset CommandInset citation
LatexCommand cite
key "grotschel2012geometric"
literal "false"

\end_inset

.
 For the most efficient known reductions,
 which are conjectured to be optimal up to logarithmic factors,
 see 
\begin_inset CommandInset citation
LatexCommand cite
key "lee2020efficient"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Section
Equivalences between Oracles
\end_layout

\begin_layout Subsection
Oracles for Convex Sets
\end_layout

\begin_layout Standard
Gr√∂tschel,
 Lov
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
'
\end_layout

\end_inset

asz and Schrijver 
\begin_inset CommandInset citation
LatexCommand cite
key "grotschel2012geometric"
literal "true"

\end_inset

 defined five different oracles to access convex sets,
 showed they are equivalent and used them to get polynomial-time algorithms for a variety of combinatorial problems (including the first ones in many cases).
 
\end_layout

\begin_layout Standard
Here are four basic oracles
\begin_inset Foot
status open

\begin_layout Plain Layout
We also omit the fifth oracle VIOL defined by 
\begin_inset CommandInset citation
LatexCommand cite
key "grotschel2012geometric"
literal "true"

\end_inset

,
 which checks whether the convex set satisfies a given inequality or gives a violating point in the convex set,
 since this is equivalent to the OPT oracle below up to a logarithmic factor.
\end_layout

\end_inset

 for a convex set 
\begin_inset Formula $K\subseteq\R^{n}$
\end_inset

.
 Later we will allow for error parameters in each oracle,
 i.e.,
 approximate versions of all the oracles below.
 We begin with exact oracles for simplicity.
\end_layout

\begin_layout Definition
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Membership Oracle (MEM)
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "def:MEM"

\end_inset

Queried with a vector 
\begin_inset Formula $y\in\Rn$
\end_inset

,
 the oracle either
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
asserts that 
\begin_inset Formula $y\in K$
\end_inset

,
 or
\end_layout

\begin_layout Itemize
asserts that 
\begin_inset Formula $y\notin K$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Separation Oracle (SEP)
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "def:SEP"

\end_inset

Queried with a vector 
\begin_inset Formula $y\in\Rn$
\end_inset

,
 the oracle either
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
asserts that 
\begin_inset Formula $y\in K$
\end_inset

,
 or
\end_layout

\begin_layout Itemize
finds a unit vector 
\begin_inset Formula $c\in\Rn$
\end_inset

 such that 
\begin_inset Formula $c^{T}x\leq c^{T}y$
\end_inset

 for all 
\begin_inset Formula $x\in K$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Validity Oracle (VAL)
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "def:VAL"

\end_inset

Queried with a unit vector 
\begin_inset Formula $c\in\Rn$
\end_inset

,
 the oracle either
\begin_inset Foot
status open

\begin_layout Plain Layout
We use a slightly different definition than 
\begin_inset CommandInset citation
LatexCommand cite
key "grotschel2012geometric"
literal "true"

\end_inset

 for clarity.
 
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
outputs 
\begin_inset Formula $\max_{x\in K}c^{\top}x$
\end_inset

,
 or
\end_layout

\begin_layout Itemize
asserts that 
\begin_inset Formula $K$
\end_inset

 is empty.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Optimization Oracle (OPT)
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "def:OPT"

\end_inset

Queried with a unit vector 
\begin_inset Formula $c\in\Rn$
\end_inset

,
 the oracle either
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
finds a vector 
\begin_inset Formula $y\in K$
\end_inset

 and 
\begin_inset Formula $c^{T}x\leq c^{T}y$
\end_inset

 for all 
\begin_inset Formula $x\in K$
\end_inset

,
 or
\end_layout

\begin_layout Itemize
asserts that 
\begin_inset Formula $K$
\end_inset

 is empty.
\end_layout

\end_deeper
\begin_layout Standard
According to the definitions,
 the separation oracle gives more information than the membership oracle and the optimization oracle gives more information than the validity oracle.
 Depending on the problem,
 usually one of the oracles will be the preferred or more natural way to access the convex set.
 For example,
 for the polytope given by 
\begin_inset Formula $\{Ax\geq b\}$
\end_inset

,
 the separation oracle is the preferred way because the membership oracle takes as much time as the separation oracle,
 and both validity and optimization involve solving a linear program.
 On the contrary,
 the preferred oracle for the convex set 
\begin_inset Formula $\conv(\{a_{i}\})$
\end_inset

 is the optimization oracle because 
\begin_inset Formula $\max_{x\in\conv(\{a_{i}\})}\theta^{\top}x$
\end_inset

 can be solved by only checking 
\begin_inset Formula $x=a_{i}$
\end_inset

 for each 
\begin_inset Formula $i$
\end_inset

.
 In combinatorial optimization,
 many polytopes have exponentially many vertices and constraints but one can use combinatorial structure to solve the optimization problem efficiently.
\end_layout

\begin_layout Example
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Zonotope
\end_layout

\end_inset

 Imagine you have 
\begin_inset Formula $n$
\end_inset

 machines.
 Each machine uses resources 
\begin_inset Formula $(r_{1},r_{2},\cdots,r_{k})\in\R_{+}^{k}$
\end_inset

 and produces goods 
\begin_inset Formula $(g_{1},g_{2},\cdots,g_{\ell})\in\R_{+}^{\ell}$
\end_inset

.
 We represent a machine simply by the vector 
\begin_inset Formula $a=(r_{1},r_{2},\cdots,r_{k},g_{1},g_{2},\cdots,g_{\ell})$
\end_inset

.
 Say we have vectors 
\begin_inset Formula $a_{1},a_{2},\cdots,a_{n}\in\R^{k+\ell}$
\end_inset

,
 then the polytope
\begin_inset Formula 
\[
K=\left\{ \sum_{i=1}^{n}\lambda_{i}a_{i}\in\R^{k+\ell}|0\leq\lambda_{i}\leq1\text{ for all }i\right\} 
\]

\end_inset

represents the set of feasible (input,
 output) pairs.
 Many production problems can then be written as
\begin_inset Formula 
\[
\min_{z\in K}f(z).
\]

\end_inset


\end_layout

\begin_layout Exercise
Evaluate the complexity of each of the basic oracles for the Zonotope problem above.
\end_layout

\begin_layout Example
The spanning tree polytope of an undirected graph 
\begin_inset Formula $G=(V,E)$
\end_inset

 is given by
\begin_inset Formula 
\[
P=\{x\in\R_{+}^{\left|E\right|}|\sum_{e\in E}x_{e}=|V|-1,\sum_{(u,v)\in E\cap(S\times S)}x_{(u,v)}\leq|S|-1\quad\forall S\subseteq V,\left|S\right|\ge1\}.
\]

\end_inset

The extreme points of this polytope can be shown to exactly correspond to the indicator vectors of spanning trees of 
\begin_inset Formula $G$
\end_inset

.
 Thus,
 the optimization oracle in this case is to simply find a maximum cost spanning tree.
\end_layout

\begin_layout Exercise
Design a membership oracle for the spanning tree polytope.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[node distance = 1.8cm]
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{block} = [rectangle,
 draw,
 text width=6.5em,
 text centered,
 rounded corners,
 minimum height=4em]
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{line} = [draw,
 -tonew,arrowhead=0.085cm]
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{dot_line} = [draw,
 -tonew,dashed,arrowhead=0.085cm]
\end_layout

\begin_layout Plain Layout

% Place nodes
\end_layout

\begin_layout Plain Layout

   
\backslash
node [block] (opt) {
\backslash
scriptsize $OPT(K) = 
\backslash
partial {
\backslash
delta_K^*}$};
\end_layout

\begin_layout Plain Layout

   
\backslash
node [block,
 below of=opt,
 node distance=1.8cm] (val) {
\backslash
scriptsize $VAL(K) = {
\backslash
delta_K^*}$};
\end_layout

\begin_layout Plain Layout

   
\backslash
node [block,
 right of=opt,
 node distance=3cm] (sepp) {
\backslash
scriptsize $SEP(K) = 
\backslash
partial{
\backslash
delta_K}$};
\end_layout

\begin_layout Plain Layout

   
\backslash
node [block,
 below of=sepp,
 node distance=1.8cm] (mem) {
\backslash
scriptsize $MEM(K) = {
\backslash
delta_K}$};
\end_layout

\begin_layout Plain Layout

   
\backslash
node [left of=opt,
 node distance=3cm] (viol) {};
\end_layout

\begin_layout Plain Layout

   
\backslash
node [below of=viol,
 node distance=1.5cm] {$
\backslash
xrightarrow{
\backslash
quad
\backslash
quad} 
\backslash
mbox{ is } 
\backslash
tilde{O}(1)$};
\end_layout

\begin_layout Plain Layout

   
\backslash
node [below of=viol,
 node distance=2.1cm] {$
\backslash
xdashrightarrow{
\backslash
quad
\backslash
quad} 
\backslash
mbox{ is } 
\backslash
tilde{O}(n)$};
 
\end_layout

\begin_layout Plain Layout

   % Draw edges
\end_layout

\begin_layout Plain Layout

%   
\backslash
path [line] (opt) -- (viol);
\end_layout

\begin_layout Plain Layout

%   
\backslash
path [line] (viol) -- (opt);
\end_layout

\begin_layout Plain Layout

   
\backslash
path [line,transform canvas={xshift=-0.25cm}] (sepp) -- (mem);
\end_layout

\begin_layout Plain Layout

   
\backslash
path [line,transform canvas={xshift=-0.25cm}] (opt) -- (val);
\end_layout

\begin_layout Plain Layout

   
\backslash
path [dot_line,transform canvas={xshift=0.25cm}] (mem) -- (sepp);
\end_layout

\begin_layout Plain Layout

   
\backslash
path [dot_line,transform canvas={xshift=0.25cm}] (val) -- (opt);
\end_layout

\begin_layout Plain Layout

   
\backslash
path [dot_line,transform canvas={yshift=-0.25cm}] (opt) -- (sepp);
\end_layout

\begin_layout Plain Layout

   
\backslash
path [dot_line,transform canvas={yshift=0.25cm}] (sepp) -- (opt);
  
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The relationships among the four oracles for convex sets.
 The arrows are implications.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:oracles"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Duals of Convex Sets
\end_layout

\begin_layout Standard
The dual or 
\emph on
polar
\emph default
 of a convex set 
\begin_inset Formula $K$
\end_inset

 is defined as the following convex set:
\begin_inset Formula 
\[
K^{*}=\left\{ y:\forall x\in K,\left\langle x,y\right\rangle \le1\right\} .
\]

\end_inset

One might imagine that the polar operator is an involution,
 i.e.,
 the dual of the dual is the original set.
 Although this is not always true,
 the set 
\begin_inset Formula $(K^{*})^{*}$
\end_inset

 still has a simple description and under mild conditions we have 
\begin_inset Formula $(K^{*})^{*}=K$
\end_inset

.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:K**"

\end_inset

 Let 
\begin_inset Formula $K\subseteq$
\end_inset


\begin_inset Formula $\,\R^{n}$
\end_inset

 be a convex set.
 Then 
\begin_inset Formula 
\[
(K^{*})^{*}=\mathrm{cl(conv(\mathit{K}\cup\left\{ 0\right\} ))}.
\]

\end_inset


\end_layout

\begin_layout Proof
We first prove that 
\begin_inset Formula $K^{**}\supseteq\mathrm{cl(conv(\mathit{K}\cup\left\{ 0\right\} ))}$
\end_inset

.
 The polar of any convex set is closed and convex since it is the intersection of halfspaces,
 which are closed and convex.
 Thus,
 to prove this part,
 it is sufficient to prove that 
\begin_inset Formula $K\subseteq K^{**}$
\end_inset

 and 
\begin_inset Formula $0\in K^{**}$
\end_inset

.
 Let 
\begin_inset Formula $x\in K$
\end_inset

.
 Then,
 for every 
\begin_inset Formula $y\in K^{*}$
\end_inset

,
 it holds that 
\begin_inset Formula $\langle x,y\rangle\leq1$
\end_inset

,
 by the definition of the polar.
 Note that these inequalities are precisely the constraints of 
\begin_inset Formula $K^{**}$
\end_inset

,
 thus 
\begin_inset Formula $x\in K^{**}$
\end_inset

 .
 Moreover,
 
\begin_inset Formula $\langle0,y\rangle=0\leq1$
\end_inset

,
 for every 
\begin_inset Formula $y\in K^{*}$
\end_inset

,
 and so 
\begin_inset Formula $0\in K^{**}$
\end_inset

.
\end_layout

\begin_layout Proof
We now prove the other direction.
 Suppose there is a vector 
\begin_inset Formula $x\in K^{**}\setminus\mathrm{cl(conv(\mathit{K}\cup\left\{ 0\right\} ))}$
\end_inset

.
 By Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:sep"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 there is 
\begin_inset Formula $\theta$
\end_inset

 such that
\begin_inset Formula 
\[
\theta^{\top}y>\max_{x\in cl(conv(\mathit{K}\cup\left\{ 0\right\} ))}\theta^{\top}x.
\]

\end_inset

Since 
\begin_inset Formula $0$
\end_inset

 is feasible,
 the RHS is at least 
\begin_inset Formula $0$
\end_inset

.
 Thus,
 
\begin_inset Formula $\theta^{\top}y>0$
\end_inset

.
 Scale 
\begin_inset Formula $\theta$
\end_inset

 so that 
\begin_inset Formula 
\[
\theta^{\top}y>1\geq\max_{x\in cl(conv(\mathit{K}\cup\left\{ 0\right\} ))}\theta^{\top}x.
\]

\end_inset

Hence,
 
\begin_inset Formula $\theta\in K^{*}$
\end_inset

 since 
\begin_inset Formula $\theta^{\top}x\leq1$
\end_inset

 for every 
\begin_inset Formula $x\in K$
\end_inset

.
 However,
 since 
\begin_inset Formula $\theta^{\top}y>1$
\end_inset

,
 we have 
\begin_inset Formula $y\not\in K^{**}$
\end_inset

,
 a contradiction.
\end_layout

\begin_layout Corollary
Let 
\begin_inset Formula $K\subseteq$
\end_inset


\begin_inset Formula $\,\R^{n}$
\end_inset

 be a closed convex set .
 Then 
\begin_inset Formula $(K^{*})^{*}=K$
\end_inset

 if and only if 
\begin_inset Formula $0\in K$
\end_inset

.
\end_layout

\begin_layout Subsection
Oracles for Convex Functions
\end_layout

\begin_layout Standard
Now,
 we generalize the oracles for convex sets to convex functions.
 The membership oracle and separation oracle can be generalized as follows
\end_layout

\begin_layout Definition
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Evaluation Oracle (EVAL)
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "def:EVAL"

\end_inset

Queried with a vector 
\begin_inset Formula $y$
\end_inset

,
 the oracle outputs 
\begin_inset Formula $f(y)$
\end_inset

.
\end_layout

\begin_layout Standard
The next oracle generalizes gradients to subgradients so that they can be computed for general convex functions.
 Any vector output by the oracle is a subgradient of the function at the query point.
\end_layout

\begin_layout Definition
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Subgradient Oracle (GRAD)
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "def:GRAD"

\end_inset

Queried with a vector 
\begin_inset Formula $y$
\end_inset

,
 the oracle outputs 
\begin_inset Formula $f(y)$
\end_inset

 and a vector 
\begin_inset Formula $g\in\Rn$
\end_inset

 such that
\begin_inset Formula 
\begin{equation}
f(x)\geq f(y)+g^{\top}(x-y)\text{ for all }x\in\Rn\label{eq:grad_guarantee}
\end{equation}

\end_inset

or outputs 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $f(y)$
\end_inset

 undefined.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
To generalize the validity oracle,
 we define the convex (Fenchel) conjugate of 
\begin_inset Formula $f$
\end_inset

:
\begin_inset Note Note
status open

\begin_layout Plain Layout
Add figure with 1-d example.
\end_layout

\end_inset


\end_layout

\begin_layout Definition
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Convex Conjugate
\end_layout

\end_inset

For any function 
\begin_inset Formula $f$
\end_inset

,
 we define the convex conjugate 
\begin_inset Formula 
\[
f^{*}(\theta)\defeq\sup_{x\in\R^{n}}\theta^{\top}x-f(x).
\]

\end_inset


\end_layout

\begin_layout Standard
Note that 
\begin_inset Formula $f^{*}$
\end_inset

 is convex because it is the supremum of linear functions.
 Also,
 we have 
\begin_inset Formula $f^{*}(0)=-\inf_{x\in\R^{n}}f(x)$
\end_inset

.
 Note that
\begin_inset Foot
status open

\begin_layout Plain Layout
Recall that 
\begin_inset Formula $\delta_{C}(x)=0$
\end_inset

 if 
\begin_inset Formula $x\in C$
\end_inset

 and 
\begin_inset Formula $+\infty$
\end_inset

 otherwise.
\end_layout

\end_inset

 
\begin_inset Formula $\delta_{K}^{*}(c)=\sup_{x\in K}c^{\top}x$
\end_inset

.
 Therefore,
 the validity oracle for 
\begin_inset Formula $\delta_{K}$
\end_inset

 is simply the evaluation oracle for 
\begin_inset Formula $\delta_{K}^{*}$
\end_inset

.
 The following lemma shows that the optimization oracle is simply the (sub)gradient oracle for 
\begin_inset Formula $\delta_{K}^{*}$
\end_inset

.
 We use 
\begin_inset Formula $\nabla f$
\end_inset

 to represent subgradient.
 
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lem:gradient_conjugate"

\end_inset

For any continuous function 
\begin_inset Formula $f$
\end_inset

 with differentiable 
\begin_inset Formula $f^{*}$
\end_inset

,
 we have that 
\begin_inset Formula $\nabla f^{*}(\theta)=\arg\max_{x}\theta^{\top}x-f(x)$
\end_inset

.
\end_layout

\begin_layout Proof
First we observe that the supremum is achieved.
 Fix 
\begin_inset Formula $\theta$
\end_inset

.
 Let 
\begin_inset Formula $g_{\theta}(x)=\theta^{\top}x-f(x)$
\end_inset

.
 We assume 
\begin_inset Formula $\sup_{x}g_{\theta}(x)=f^{*}(\theta)$
\end_inset

 is finite.
 Let 
\begin_inset Formula $\epsilon>0$
\end_inset

.
 Then,
 
\begin_inset Formula $g_{\theta}(x)$
\end_inset

 is a continuous function,
 so 
\begin_inset Formula $S=g_{\theta}^{-1}([f^{*}(\theta)-\epsilon,\infty))$
\end_inset

 is a closed set.
 The set 
\begin_inset Formula $S$
\end_inset

 is not empty because there is some 
\begin_inset Formula $x$
\end_inset

 for which 
\begin_inset Formula $g_{\theta}(x)\ge\sup_{z}g_{\theta}(z)-\epsilon$
\end_inset

.
 Now suppose for a contradiction that 
\begin_inset Formula $S$
\end_inset

 is not bounded.
 Then,
 there exists a sequence 
\begin_inset Formula $x_{i}\in\R^{n}$
\end_inset

 such that 
\begin_inset Formula $\norm{x_{i}}\ge i$
\end_inset

 and 
\begin_inset Formula $g_{\theta}(x_{i})\ge f^{*}(\theta)-\epsilon$
\end_inset

 for all 
\begin_inset Formula $i$
\end_inset

.
 By the compactness of the unit sphere,
 we may assume by taking a subsequence that 
\begin_inset Formula $x_{i}/\lVert x_{i}\rVert\to u$
\end_inset

 for some unit vector 
\begin_inset Formula $u\in\R^{n}$
\end_inset

.
 Then,
 
\begin_inset Formula $u^{\top}x_{i}/\lVert x_{i}\rVert\to u^{\top}u=1$
\end_inset

,
 and since 
\begin_inset Formula $\lVert x_{i}\rVert\to\infty$
\end_inset

,
 we have 
\begin_inset Formula $u^{\top}x_{i}\to\infty$
\end_inset

.
 Since 
\begin_inset Formula $g_{\theta+u}(x_{i})=g_{\theta}(x_{i})+u^{\top}x_{i}\ge f^{*}(\theta)-\epsilon+u^{\top}x_{i}$
\end_inset

,
 this means that 
\begin_inset Formula $g_{\theta+u}(x_{i})\to\infty$
\end_inset

,
 contradicting 
\begin_inset Formula $f^{*}(\theta+u)$
\end_inset

 being finite.
 Hence,
 
\begin_inset Formula $S$
\end_inset

 is bounded and thus compact,
 so 
\begin_inset Formula $g_{\theta}(x)$
\end_inset

 attains its maximum in 
\begin_inset Formula $S$
\end_inset

,
 and thus in 
\begin_inset Formula $\R^{n}$
\end_inset

.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $x_{\theta}\in\arg\sup_{x}\theta^{\top}x-f(x)$
\end_inset

.
 By definition,
 we have that 
\begin_inset Formula $f^{*}(\theta)=\theta^{\top}x_{\theta}-f(x_{\theta})$
\end_inset

 and that 
\begin_inset Formula $f^{*}(\eta)\geq\eta^{\top}x_{\theta}-f(x_{\theta})$
\end_inset

 for all 
\begin_inset Formula $\eta$
\end_inset

.
 Therefore,
 
\begin_inset Formula 
\[
f^{*}(\eta)\geq f^{*}(\theta)+x_{\theta}^{\top}(\eta-\theta)\text{ for all }\eta.
\]

\end_inset

Therefore,
 
\begin_inset Formula $x_{\theta}\in\nabla f^{*}(\theta)$
\end_inset

.
\end_layout

\begin_layout Standard
Note that this lemma shows that 
\begin_inset Formula $\nabla\delta_{K}^{*}(\theta)=\arg\max_{x\in K}\theta^{\top}x$
\end_inset

.
 So,
 the gradient oracle for 
\begin_inset Formula $\delta_{K}^{*}$
\end_inset

 is exactly the optimization oracle for 
\begin_inset Formula $K$
\end_inset

.
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:rel"
nolink "false"

\end_inset

 shows the current best reduction between these four function oracles.
 Note that according to our definition of the GRAD oracle,
 it also outputs the function value (EVAL).
 It is not hard to show that you can use 
\begin_inset Formula $n+1$
\end_inset

 calls to evaluation oracle to compute one gradient approximately (using finite difference) and that you can use 
\begin_inset Formula $\tilde{O}(n)$
\end_inset

 calls to gradient oracle of 
\begin_inset Formula $f$
\end_inset

 to compute one gradient of 
\begin_inset Formula $f^{*}$
\end_inset

 (using the cutting plane method).
 In the next section (Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:From-EVAL-to"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 we will see the remaining reductions.
 However,
 it is still an open question if all of these reductions are the best possible.
 
\end_layout

\begin_layout Problem*
Prove that it takes 
\begin_inset Formula $\Omega(n^{2})$
\end_inset

 calls to the evaluation oracle of 
\begin_inset Formula $f$
\end_inset

 to compute the gradient of 
\begin_inset Formula $f^{*}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[node distance = 1.8cm]
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{block} = [rectangle,
 draw,
 text width=6.5em,
 text centered,
 rounded corners,
 minimum height=4em]
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{line} = [draw,
 -tonew,arrowhead=0.085cm]
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{dot_line} = [draw,
 -tonew,dashed,arrowhead=0.085cm]
\end_layout

\begin_layout Plain Layout

% Place nodes
\end_layout

\begin_layout Plain Layout

   
\backslash
node [block] (opt) {
\backslash
scriptsize $GRAD(f^*)$};
\end_layout

\begin_layout Plain Layout

   
\backslash
node [block,
 below of=opt,
 node distance=1.8cm] (val) {
\backslash
scriptsize $EVAL(f^*)$};
\end_layout

\begin_layout Plain Layout

   
\backslash
node [block,
 right of=opt,
 node distance=3cm] (sepp) {
\backslash
scriptsize $GRAD(f)$};
\end_layout

\begin_layout Plain Layout

   
\backslash
node [block,
 below of=sepp,
 node distance=1.8cm] (mem) {
\backslash
scriptsize $EVAL(f)$};
\end_layout

\begin_layout Plain Layout

   
\backslash
node [left of=opt,
 node distance=3cm] (viol) {};
\end_layout

\begin_layout Plain Layout

   
\backslash
node [below of=viol,
 node distance=1.5cm] {$
\backslash
xrightarrow{
\backslash
quad
\backslash
quad} 
\backslash
mbox{ is } 
\backslash
tilde{O}(1)$};
\end_layout

\begin_layout Plain Layout

   
\backslash
node [below of=viol,
 node distance=2.1cm] {$
\backslash
xdashrightarrow{
\backslash
quad
\backslash
quad} 
\backslash
mbox{ is } 
\backslash
tilde{O}(n)$};
 
\end_layout

\begin_layout Plain Layout

   %
\backslash
node [below of=viol,
 node distance=1.5cm] {$
\backslash
tilde{O}(1) 
\backslash
xrightarrow{
\backslash
quad
\backslash
quad}$};
\end_layout

\begin_layout Plain Layout

   %
\backslash
node [below of=viol,
 node distance=2.1cm] {$
\backslash
tilde{O}(n) 
\backslash
xdashrightarrow{
\backslash
quad
\backslash
quad}$};
 
\end_layout

\begin_layout Plain Layout

   % Draw edges
\end_layout

\begin_layout Plain Layout

   
\backslash
path [line,transform canvas={xshift=-0.25cm}] (sepp) -- (mem);
\end_layout

\begin_layout Plain Layout

   
\backslash
path [line,transform canvas={xshift=-0.25cm}] (opt) -- (val);
\end_layout

\begin_layout Plain Layout

   
\backslash
path [dot_line,transform canvas={xshift=0.25cm}] (mem) -- (sepp);
\end_layout

\begin_layout Plain Layout

   
\backslash
path [dot_line,transform canvas={xshift=0.25cm}] (val) -- (opt);
\end_layout

\begin_layout Plain Layout

   
\backslash
path [dot_line,transform canvas={yshift=-0.25cm}] (opt) -- (sepp);
\end_layout

\begin_layout Plain Layout

   
\backslash
path [dot_line,transform canvas={yshift=0.25cm}] (sepp) -- (opt);
  
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
This illustrates the relationships of oracles for a convex function 
\begin_inset Formula $f$
\end_inset

 and its convex conjugate 
\begin_inset Formula $f^{*}$
\end_inset

.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:rel"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Convex Conjugate and Equivalences
\end_layout

\begin_layout Standard
Here are some examples of conjugates.
\end_layout

\begin_layout Exercise
Show that
\end_layout

\begin_layout Itemize
The conjugate of 
\begin_inset Formula $f(x)=\frac{1}{p}\|x\|_{p}^{p}$
\end_inset

 is 
\begin_inset Formula $f^{*}(\theta)=\frac{1}{q}\|\theta\|_{q}^{q}$
\end_inset

 where 
\begin_inset Formula $\frac{1}{p}+\frac{1}{q}=1$
\end_inset

 (with 
\begin_inset Formula $p,q\ge1)$
\end_inset

.
\end_layout

\begin_layout Itemize
The conjugate of 
\begin_inset Formula $f(x)=\left\langle a,x\right\rangle -b$
\end_inset

 is 
\begin_inset Formula $f^{*}(\theta)=\begin{cases}
b, & \theta=a\\
+\infty & \mbox{otherwise}
\end{cases}$
\end_inset

.
\end_layout

\begin_layout Itemize
The conjugate of 
\begin_inset Formula $f(x)=\sum_{i}e^{x_{i}}$
\end_inset

 is 
\begin_inset Formula $f^{*}(\theta)=\begin{cases}
\sum_{i}\theta_{i}\log\theta_{i}-\theta_{i} & \text{if }\theta_{i}\geq0\text{ for all }i\\
+\infty & \mbox{otherwise}
\end{cases}.$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Exercise
For any 
\begin_inset Formula $x,\theta$
\end_inset

,
 we have 
\begin_inset Formula $\theta^{\top}x\leq f(x)+f^{*}(\theta)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Exercise
Prove that the gradient of 
\begin_inset Formula $f$
\end_inset

 is 
\begin_inset Formula $L$
\end_inset

-Lipschitz if and only if 
\begin_inset Formula $f^{*}$
\end_inset

 is 
\begin_inset Formula $\frac{1}{L}$
\end_inset

 strongly convex.
\end_layout

\begin_layout Standard
The following lemma shows that one can recover 
\begin_inset Formula $f$
\end_inset

 from 
\begin_inset Formula $f^{*}$
\end_inset

.
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lem:involution"

\end_inset


\begin_inset Argument 1
status open

\begin_layout Plain Layout
Involution property
\end_layout

\end_inset

For any convex function 
\begin_inset Formula $f$
\end_inset

 with a closed epigraph,
 we have that 
\begin_inset Formula $f^{**}=f$
\end_inset

.
\end_layout

\begin_layout Proof
\begin_inset Note Note
status open

\begin_layout Plain Layout
The proof is not completely rigorous.
 There can be a vertical cutting plane
\end_layout

\end_inset

Since 
\begin_inset Formula $\epi f$
\end_inset

 is a closed,
 convex set,
 Corollary 
\begin_inset CommandInset ref
LatexCommand ref
reference "cor:convex_function_intersection"
nolink "false"

\end_inset

 shows that it must be an intersection of halfspaces,
 i.e.,
 a set 
\begin_inset Formula ${\cal H}$
\end_inset

 s.t.
 
\begin_inset Formula 
\[
f(x)=\sup_{(\theta,b)\in\mathcal{H}}\theta^{\top}x-b
\]

\end_inset

where 
\begin_inset Formula $\mathcal{H}$
\end_inset

 is the set of supporting planes of 
\begin_inset Formula $\epi f$
\end_inset

 and contains all affine lower bounds on 
\begin_inset Formula $f$
\end_inset

,
 namely,
 
\begin_inset Formula $f(x)\geq\theta^{\top}x-b$
\end_inset

 for all 
\begin_inset Formula $x$
\end_inset

.
 Alternatively,
 we can write
\begin_inset Formula 
\[
\epi(f)=\bigcap_{{\cal H}=\left\{ (\theta,b):\,\forall x,\,f(x)\ge\theta^{\top}x-b\right\} }\left\{ (x,t):t\ge\theta^{\top}x-b\right\} .
\]

\end_inset

For a fixed 
\begin_inset Formula $\theta$
\end_inset

,
 any feasible 
\begin_inset Formula $b$
\end_inset

 satisfies 
\begin_inset Formula $b\geq\theta^{\top}x-f(x)$
\end_inset

 for all 
\begin_inset Formula $x$
\end_inset

.
 So,
 the smallest feasible value satisfies 
\begin_inset Formula 
\[
b^{*}=\sup_{x}\theta^{\top}x-f(x)=f^{*}(\theta).
\]

\end_inset

Hence,
 
\begin_inset Formula 
\[
f(x)=\sup_{(\theta,b)\in\mathcal{H}}\theta^{\top}x-b^{*}=\sup_{\theta}\theta^{\top}x-f^{*}(\theta)=f^{**}(x).
\]

\end_inset


\end_layout

\begin_layout Exercise
Let 
\begin_inset Formula $f$
\end_inset

 be a convex function with closed epigraph.
 Show that 
\begin_inset Formula $f=f^{*}$
\end_inset

 iff 
\begin_inset Formula $f(x)=\frac{\norm x^{2}}{2}$
\end_inset

.
\end_layout

\begin_layout Standard
Since we can use the gradient,
 
\begin_inset Formula $\nabla f$
\end_inset

,
 to compute the gradient of the dual,
 
\begin_inset Formula $\nabla f^{*}$
\end_inset

 (via cutting plane method)
\begin_inset Note Note
status open

\begin_layout Plain Layout
Maybe make this part more explicit with an algorithm box?
\end_layout

\end_inset

,
 the involution property shows that we can do the reverse ‚Äì use 
\begin_inset Formula $\nabla f^{*}$
\end_inset

 to compute 
\begin_inset Formula $\nabla f$
\end_inset

.
 Going back to the example about 
\begin_inset Formula $\conv(\{a_{i}\})$
\end_inset

,
 since we know how to compute 
\begin_inset Formula $\max_{x\in\conv(\{a_{i}\})}\theta^{\top}x=\delta_{\conv(\{a_{i}\})}^{*}(\theta)$
\end_inset

,
 this reduction gives us a way to separate 
\begin_inset Formula $\conv(\{a_{i}\})$
\end_inset

,
 or equivalently,
 to compute the (sub)gradient of 
\begin_inset Formula $\delta_{\conv(\{a_{i}\})}^{*}$
\end_inset

.
 This is formalized in the next exercise.
\end_layout

\begin_layout Exercise
Show how to implement the separation oracle SEP for a convex set 
\begin_inset Formula $K$
\end_inset

 given access to an optimization oracle OPT for 
\begin_inset Formula $K$
\end_inset

.
\end_layout

\begin_layout Standard
Recall that for any linear space 
\begin_inset Formula $X$
\end_inset

,
 
\begin_inset Formula $X^{*}$
\end_inset

 denotes the dual space,
 i.e.,
 the set of all linear functions on 
\begin_inset Formula $X$
\end_inset

 and that under mild assumptions
\begin_inset Foot
status open

\begin_layout Plain Layout
The dual of the dual of a vector space 
\begin_inset Formula $X$
\end_inset

 is isomorphic to 
\begin_inset Formula $X$
\end_inset

 if and only if 
\begin_inset Formula $X$
\end_inset

 is a finite-dimensional vector space.
\end_layout

\end_inset

,
 we have 
\begin_inset Formula $X^{**}=X$
\end_inset

.
 Therefore,
 there are two natural 
\begin_inset Quotes eld
\end_inset

coordinate systems
\begin_inset Quotes erd
\end_inset

 to record a convex function,
 the primal space 
\begin_inset Formula $X$
\end_inset

 and the dual space 
\begin_inset Formula $X^{*}$
\end_inset

.
 Under these 
\begin_inset Quotes eld
\end_inset

coordinate systems
\begin_inset Quotes erd
\end_inset

,
 we have the dual functions 
\begin_inset Formula $f$
\end_inset

 and 
\begin_inset Formula $f^{*}$
\end_inset

.
\end_layout

\begin_layout Exercise
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Order reversal
\end_layout

\end_inset

 Show that 
\begin_inset Formula $f\geq g\iff f^{*}\leq g^{*}$
\end_inset

 (both for all 
\begin_inset Formula $x\in\R^{n})$
\end_inset

.
\end_layout

\begin_layout Exercise
Interestingly,
 the convex conjugate is the 
\emph on
unique
\emph default
 transformation on convex functions that satisfies both involution and order reversal.
 
\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "artstein2009concept"
literal "true"

\end_inset


\end_layout

\end_inset

Given a transformation 
\begin_inset Formula $\mathcal{T}$
\end_inset

 that maps the set of lower semi-continuous
\begin_inset Foot
status open

\begin_layout Plain Layout
See Def.
\begin_inset CommandInset ref
LatexCommand ref
reference "def:lower-semi"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\end_inset

 convex functions onto itself such that 
\begin_inset Formula $\mathcal{T}\mathcal{T}\phi=\phi$
\end_inset

 and 
\begin_inset Formula $\phi\leq\psi\implies\mathcal{T}\phi\geq\mathcal{T}\psi$
\end_inset

 for all lower-semi-continuous convex functions 
\begin_inset Formula $\phi$
\end_inset

 and 
\begin_inset Formula $\psi$
\end_inset

.
 Then,
 
\begin_inset Formula $\mathcal{T}$
\end_inset

 is essentially the convex conjugate,
 namely,
 there is an invertible symmetric linear transformation 
\begin_inset Formula $B$
\end_inset

,
 a vector 
\begin_inset Formula $v_{0}$
\end_inset

 and a constant 
\begin_inset Formula $C_{0}$
\end_inset

 such that 
\begin_inset Formula 
\[
(\mathcal{T}\phi)(x)=\phi^{*}(Bx+v_{0})+v_{0}^{\top}x+C_{0}.
\]

\end_inset


\end_layout

\begin_layout Standard
In combinatorial optimization,
 many convex sets are given by the convex hull for some discrete objects.
 In many cases,
 the only known way to do the separation is via such reductions.
 In this chapter,
 we will study the following general theorem showing that optimization can be reduced to membership/evaluation with a quadratic overhead in dimension for the number of oracle queries.
 
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $K$
\end_inset

 be a convex set specified by a membership oracle,
 a point 
\begin_inset Formula $x_{0}\in\R^{n}$
\end_inset

,
 and numbers 
\begin_inset Formula $0<r<R$
\end_inset

 such that 
\begin_inset Formula $B(x_{0},r)\subseteq K\subseteq B(x_{0},R)$
\end_inset

.
 For any convex function 
\begin_inset Formula $f$
\end_inset

 given by an evaluation oracle and any 
\begin_inset Formula $\epsilon>0$
\end_inset

,
 there is a randomized algorithm that computes a point 
\begin_inset Formula $z\in B(K,\epsilon)$
\end_inset

 such that.
 
\begin_inset Formula 
\[
f(z)\le\min_{x\in K}f(x)+\epsilon\left(\max_{x\in K}f(x)-\min_{x\in K}f(x)\right)
\]

\end_inset

with constant probability using 
\begin_inset Formula $O\left(n^{2}\log^{2}\left(\frac{nR}{\epsilon r}\right)\right)$
\end_inset

 calls to the membership oracle and evaluation oracle and 
\begin_inset Formula $O(n^{3}\log^{O(1)}\left(\frac{nR}{\epsilon r}\right))$
\end_inset

 total arithmetic operations.
 
\end_layout

\begin_layout Section
Gradient from Evaluation via Finite Difference
\begin_inset CommandInset label
LatexCommand label
name "sec:From-EVAL-to"

\end_inset


\end_layout

\begin_layout Standard
When the function 
\begin_inset Formula $f$
\end_inset

 is in 
\begin_inset Formula $\mathcal{C}^{1}$
\end_inset

,
 we can approximate the gradient of a function by calculating a finite difference for sufficiently small 
\begin_inset Formula $h$
\end_inset

:
\begin_inset Formula 
\[
\frac{\partial f}{\partial x_{i}}=\frac{f(x+he_{i})-f(x)}{h}+O(h)
\]

\end_inset

which only takes 
\begin_inset Formula $n+1$
\end_inset

 calls to the evaluation oracle (for computing 
\begin_inset Formula $f(x),f(x+he_{1}),\cdots,f(x+he_{n})$
\end_inset

).
 The only issue is that the convex function may not be differentiable.
 However,
 any convex Lipschitz function is twice differentiable almost everywhere (see the proof below).
 Therefore,
 we can simply perturb 
\begin_inset Formula $x$
\end_inset

 with random noise,
 then apply a finite difference.
 To see the idea more precisely,
 we first observe that the norm of the Hessian can be bounded in expectation for a Lipschitz function.
 Note that this is Lipschitzness of the function,
 not its gradient.
 The proof below uses the basic fact that the gradient is defined almost everywhere for Lipschitz functions.
 
\end_layout

\begin_layout Lemma
For any 
\begin_inset Formula $L$
\end_inset

-Lipschitz convex function 
\begin_inset Formula $f$
\end_inset

 defined in a unit ball,
 we have 
\begin_inset Formula $\nabla^{2}f(x)$
\end_inset

 exists almost everywhere and that 
\begin_inset Formula $\E_{x\in B(0,1)}\|\nabla^{2}f(x)\|_{F}\leq nL$
\end_inset

.
\end_layout

\begin_layout Proof
The existence almost everywhere is classical (Alexandrov Theorem,
 see e.g.,
 
\begin_inset CommandInset citation
LatexCommand cite
key "constantin2018convex"
literal "false"

\end_inset

;
 see also Rademacher's theorem about the existence of the derivative almost everywhere for Lipschitz functions).
 We will only prove the part 
\begin_inset Formula $\E_{x\in B(0,1)}\|\nabla^{2}f(x)\|_{F}\leq nL$
\end_inset

.
 Since 
\begin_inset Formula $\nabla^{2}f\succeq0$
\end_inset

 (where defined),
 we have 
\begin_inset Formula $\|\nabla^{2}f(x)\|_{F}\leq\tr\nabla^{2}f(x)$
\end_inset

.
 Therefore,
 
\begin_inset Formula 
\[
\int_{B(0,1)}\|\nabla^{2}f(x)\|_{F}dx\leq\int_{B(0,1)}\tr\nabla^{2}f(x)dx=\int_{B(0,1)}\Delta f(x)dx.
\]

\end_inset

Using Stokes' Theorem,
 and letting 
\begin_inset Formula $\nu(x)$
\end_inset

 be the normal vector at 
\begin_inset Formula $x$
\end_inset

,
 we have 
\begin_inset Formula 
\[
\int_{B(0,1)}\Delta f(x)dx=\int_{\partial B(0,1)}\left\langle \nabla f(x),\nu(x)\right\rangle dx\leq|\partial B(0,1)|\cdot L.
\]

\end_inset

Hence,
 we have
\begin_inset Formula 
\[
\E_{x\in B(0,1)}\|\nabla^{2}f(x)\|_{F}\leq\frac{|\partial B(0,1)|}{|B(0,1)|}L=nL.
\]

\end_inset


\end_layout

\begin_layout Standard
To turn this into an algorithm,
 we need to develop it a bit further.
\end_layout

\begin_layout Lemma
\begin_inset Argument 1
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "lee2017efficient"
literal "true"

\end_inset


\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "lem:convex_almost_flat"

\end_inset

Let 
\begin_inset Formula $B_{\infty}(x,r)=\{y:\ \norm{x-y}_{\infty}\leq r\}$
\end_inset

.
 For any 
\begin_inset Formula $0<r_{2}\leq r_{1}$
\end_inset

 and any convex function 
\begin_inset Formula $f$
\end_inset

 defined on 
\begin_inset Formula $B_{\infty}(x,r_{1}+r_{2})$
\end_inset

 with 
\begin_inset Formula $\norm{\nabla f(z)}_{\infty}\leq L$
\end_inset

 for any 
\begin_inset Formula $z\in B_{\infty}(x,r_{1}+r_{2})$
\end_inset

 we have 
\begin_inset Formula 
\[
\E_{y\in B_{\infty}(x,r_{1})}\E_{z\in B_{\infty}(y,r_{2})}\norm{\nabla f(z)-g(y)}_{1}\leq n^{3/2}\frac{r_{2}}{r_{1}}L
\]

\end_inset

where 
\begin_inset Formula $g(y)$
\end_inset

 is the average of 
\begin_inset Formula $\nabla f$
\end_inset

 over 
\begin_inset Formula $B_{\infty}(y,r_{2})$
\end_inset

.
\end_layout

\begin_layout Lemma
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Figures/Lemma_4.21.png
	width 60col%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $\omega_{i}(z)=\left\langle \nabla f(z)-g(y),e_{i}\right\rangle $
\end_inset

 for all 
\begin_inset Formula $i\in[n]$
\end_inset

.
 Then,
 we have that
\begin_inset Formula 
\[
\int_{B_{\infty}(y,r_{2})}\norm{\nabla f(z)-g(y)}_{1}dz=\sum_{i}\int_{B_{\infty}(y,r_{2})}\left|\omega_{i}(z)\right|dz.
\]

\end_inset

Since 
\begin_inset Formula $\int_{B_{\infty}(y,r_{2})}\omega_{i}(z)dz=0$
\end_inset

,
 the Poincar
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
'e
\end_layout

\end_inset

 inequality for a box (Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:box-poincare"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 below) shows that
\begin_inset Formula 
\begin{align*}
\int_{B_{\infty}(y,r_{2})}\left|\omega_{i}(z)\right|dz & \leq r_{2}\int_{B_{\infty}(y,r_{2})}\norm{\nabla\omega_{i}(z)}_{2}dz\\
 & =r_{2}\int_{B_{\infty}(y,r_{2})}\norm{\nabla^{2}f(z)e_{i}}_{2}dz\\
\sum_{i}\int_{B_{\infty}(y,r_{2})}\left|\omega_{i}(z)\right|dz & \le\sqrt{n}r_{2}\int_{B_{\infty}(y,r_{2})}\norm{\nabla^{2}f(z)}_{F}dz
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $f$
\end_inset

 is convex,
 eigenvalues of the Hessian are nonnegative and so we have 
\begin_inset Formula 
\[
\norm{\nabla^{2}f(z)}_{F}=\sqrt{\sum_{i}\lambda_{i}^{2}}\le\sum_{i}\lambda_{i}=\tr\nabla^{2}f(z)=\Delta f(z).
\]

\end_inset

Therefore,
 we have
\begin_inset Formula 
\begin{align*}
\E_{z\in B_{\infty}(y,r_{2})}\norm{\nabla f(z)-g(y)}_{1} & \leq\sqrt{n}r_{2}\E_{z\in B_{\infty}(y,r_{2})}\Delta f(z)\\
 & =\sqrt{n}r_{2}\Delta h(y)
\end{align*}

\end_inset

where 
\begin_inset Formula $h=\frac{1}{(2r_{2})^{n}}f\ast\chi_{B_{\infty}(0,r_{2})}$
\end_inset

 where 
\begin_inset Formula $\chi_{B_{\infty}(0,r_{2})}$
\end_inset

 is 
\begin_inset Formula $1$
\end_inset

 on the set 
\begin_inset Formula $B_{\infty}(0,r_{2})$
\end_inset

 and 
\begin_inset Formula $0$
\end_inset

 on outside.
\end_layout

\begin_layout Proof
Integrating by parts,
 we have that
\begin_inset Formula 
\[
\int_{B_{\infty}(x,r_{1})}\Delta h(y)dy=\int_{\partial B_{\infty}(x,r_{1})}\left\langle \nabla h(y),n(y)\right\rangle dy
\]

\end_inset

where 
\begin_inset Formula $\Delta h(y)=\sum_{i}\frac{d^{2}h}{dx_{i}^{2}}(y)$
\end_inset

 and 
\begin_inset Formula $n(y)$
\end_inset

 is the normal vector on 
\begin_inset Formula $\partial B_{\infty}(x,r_{1})$
\end_inset

 the boundary of the box 
\begin_inset Formula $B_{\infty}(x,r_{1})$
\end_inset

,
 i.e.
 standard basis vectors.
 Since 
\begin_inset Formula $f$
\end_inset

 is 
\begin_inset Formula $L$
\end_inset

-Lipschitz with respect to 
\begin_inset Formula $\norm{\cdot}_{\infty}$
\end_inset

 so is 
\begin_inset Formula $h$
\end_inset

,
 i.e.
 
\begin_inset Formula $\norm{\nabla h(z)}_{\infty}\leq L$
\end_inset

.
 Hence,
 we have that
\begin_inset Formula 
\[
\E_{y\in B_{\infty}(x,r_{1})}\Delta h(y)\leq\frac{1}{(2r_{1})^{n}}\int_{\partial B_{\infty}(x,r_{1})}\norm{\nabla h(y)}_{\infty}\norm{n(y)}_{1}dy\leq\frac{1}{(2r_{1})^{n}}\cdot2n(2r_{1})^{n-1}\cdot L=\frac{nL}{r_{1}}.
\]

\end_inset

Therefore,
 we have that
\begin_inset Formula 
\[
\E_{y\in B_{\infty}(x,r_{1})}\E_{z\in B_{\infty}(y,r_{2})}\norm{\nabla f(z)-g(y)}_{1}\leq n^{3/2}\frac{r_{2}}{r_{1}}L.
\]

\end_inset


\end_layout

\begin_layout Exercise
For an 
\begin_inset Formula $L$
\end_inset

-gradient-Lipschitz function 
\begin_inset Formula $f:\R^{n}\rightarrow\R,$
\end_inset

and 
\begin_inset Formula $h=f*\chi_{B_{\infty}(0,1/2)}$
\end_inset

,
 prove that 
\begin_inset Formula $h$
\end_inset

 is also 
\begin_inset Formula $L$
\end_inset

-gradient-Lipschitz and 
\begin_inset Formula $\Delta h(y)=\E_{z\sim B_{\infty(y,1/2)}}(\Delta f(z))$
\end_inset

.
\end_layout

\begin_layout Standard
This lemma shows that we can implement an approximate gradient oracle (GRAD) using an evaluation oracle (EVAL) even for non-differentiable functions.
 By the involution property again,
 this completes all the reductions in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:rel"
nolink "false"

\end_inset

.
 With the above fact asserting that,
 on average,
 the gradient is approximated by its average in a small ball,
 we now proceed to construct an approximate subgradient,
 using only an approximate evaluation oracle.
 The parameter 
\begin_inset Formula $r_{2}$
\end_inset

 in the algorithm is chosen to optimize the final error of the output.
 By making the ratio 
\begin_inset Formula $r_{2}/r_{1}$
\end_inset

 sufficiently small,
 we can get a desired error for the subgradient.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithm2e}[t]
\end_layout

\end_inset

 
\begin_inset CommandInset label
LatexCommand label
name "alg:separateFunc"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
caption{
\end_layout

\end_inset


\begin_inset Formula $\mathtt{SubgradConvexFunc}(f,x,r_{1},\varepsilon)$
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
SetAlgoLined
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
Require:

\series default
 
\begin_inset Formula $r_{1}>0$
\end_inset

,
 
\begin_inset Formula $\norm{\partial f(z)}_{\infty}\leq L$
\end_inset

 for any 
\begin_inset Formula $z\in B_{\infty}(x,2r_{1})$
\end_inset

.
\end_layout

\begin_layout Standard
Set 
\begin_inset Formula $r_{2}=\sqrt{\frac{\varepsilon r_{1}}{\sqrt{n}L}}$
\end_inset

.
\end_layout

\begin_layout Standard
Sample 
\begin_inset Formula $y\in B_{\infty}(x,r_{1})$
\end_inset

 and 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $z\in B_{\infty}(y,r_{2})$
\end_inset

 independently and uniformly at random.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
For{
\end_layout

\end_inset


\begin_inset Formula $i=1,2,\cdots,n$
\end_inset

 
\begin_inset ERT
status open

\begin_layout Plain Layout

}{
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\alpha_{i}$
\end_inset

 and 
\begin_inset Formula $\beta_{i}$
\end_inset

 denote the end points of the interval 
\begin_inset Formula $B_{\infty}(y,r_{2})\cap\{z+se_{i}:s\in\R\}$
\end_inset

.
\end_layout

\begin_layout Standard
Set 
\begin_inset Formula $\tilde{g}_{i}=\frac{f(\beta_{i})-f(\alpha_{i})}{2r_{2}}$
\end_inset

 where we compute 
\begin_inset Formula $f$
\end_inset

 to within 
\begin_inset Formula $\varepsilon$
\end_inset

 additive error.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
Output
\series default
 
\begin_inset Formula $\tilde{g}$
\end_inset

 as the approximate subgradient of 
\begin_inset Formula $f$
\end_inset

 at 
\begin_inset Formula $x$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{algorithm2e}
\end_layout

\end_inset


\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lem:separate_conv_func"

\end_inset

 Let 
\begin_inset Formula $r_{1}>0$
\end_inset

 and 
\begin_inset Formula $f$
\end_inset

 be a convex function
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
on 
\begin_inset Formula $B_{\infty}(x,2r_{1})$
\end_inset


\end_layout

\end_inset

.
 Suppose that 
\begin_inset Formula $\norm{\nabla f(z)}_{\infty}\leq L$
\end_inset

 for any 
\begin_inset Formula $z\in B_{\infty}(x,2r_{1})$
\end_inset

 and suppose that we can evaluate f to within 
\begin_inset Formula $\varepsilon$
\end_inset

 additive error for 
\begin_inset Formula $\varepsilon\leq r_{1}\sqrt{n}L$
\end_inset

.
 Let 
\begin_inset Formula $\tilde{g}=\mathtt{SubgradConvexFunc}(f,x,r_{1},\varepsilon)$
\end_inset

.
 Then,
 there is random variable 
\begin_inset Formula $\zeta\geq0$
\end_inset

 with 
\begin_inset Formula $\E\zeta\leq2\sqrt{\frac{L\varepsilon}{r_{1}}}n^{5/4}$
\end_inset

 such that for any 
\begin_inset Formula $y$
\end_inset


\begin_inset Formula 
\[
f(y)\geq f(x)+\left\langle \tilde{g},y-x\right\rangle -\zeta\norm{y-x}_{\infty}-4nr_{1}L.
\]

\end_inset


\end_layout

\begin_layout Proof
We assume that 
\begin_inset Formula $f$
\end_inset

 is twice differentiable.
 For general 
\begin_inset Formula $f$
\end_inset

,
 we can reduce to this case by viewing it as a limit of twice-differentiable functions.
\end_layout

\begin_layout Proof
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Figures/Lemma_4.23.png
	width 60col%

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Proof
First,
 we assume that we can compute 
\begin_inset Formula $f$
\end_inset

 exactly,
 namely 
\begin_inset Formula $\varepsilon=0$
\end_inset

.
 Fix 
\begin_inset Formula $i\in[n]$
\end_inset

.
 Let 
\begin_inset Formula $g(y)$
\end_inset

 be the average of 
\begin_inset Formula $\nabla f$
\end_inset

 over 
\begin_inset Formula $B_{\infty}(y,r_{2})$
\end_inset

.
 Then,
 for the function 
\begin_inset Formula $\tilde{g}$
\end_inset

 computed by the algorithm,
 we have that
\begin_inset Formula 
\begin{align*}
\E_{z}\left|\tilde{g}_{i}-g(y)_{i}\right| & =\E_{z}\left|\frac{f(\beta_{i})-f(\alpha_{i})}{2r_{2}}-g(y)_{i}\right|\\
 & \leq\E_{z}\frac{1}{2r_{2}}\int\left|\frac{df}{dx_{i}}(z+se_{i})-g(y)_{i}\right|ds\\
 & =\E_{z}\left|\frac{df}{dx_{i}}(z)-g(y)_{i}\right|
\end{align*}

\end_inset

where we used that both 
\begin_inset Formula $z+se_{i}$
\end_inset

 and 
\begin_inset Formula $z$
\end_inset

 are uniform distribution on 
\begin_inset Formula $B_{\infty}(y,r_{2})$
\end_inset

 in the last line.
 Hence,
 we have
\begin_inset Formula 
\[
\E_{z}\norm{\tilde{g}-\nabla f(z)}_{1}\leq\E_{z}\norm{\nabla f(z)-g(y)}_{1}+\E_{z}\norm{\tilde{g}-g(y)}_{1}\leq2\E_{z}\norm{\nabla f(z)-g(y)}_{1}.
\]

\end_inset

Now,
 applying the convexity of 
\begin_inset Formula $f$
\end_inset

 yields that
\begin_inset Formula 
\begin{align*}
f(q) & \geq f(z)+\left\langle \nabla f(z),q-z\right\rangle \\
 & =f(z)+\left\langle \tilde{g},q-x\right\rangle +\left\langle \nabla f(z)-\tilde{g},q-x\right\rangle +\left\langle \nabla f(z),x-z\right\rangle \\
 & \geq f(z)+\left\langle \tilde{g},q-x\right\rangle -\norm{\nabla f(z)-\tilde{g}}_{1}\norm{q-x}_{\infty}-\norm{\nabla f(z)}_{\infty}\norm{x-z}_{1}.
\end{align*}

\end_inset

Now,
 using 
\begin_inset Formula $f$
\end_inset

 is 
\begin_inset Formula $L$
\end_inset

-Lipschitz between 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $z$
\end_inset

,
 we have that 
\begin_inset Formula $f(z)\geq f(x)-L\cdot\norm{x-z}_{1}$
\end_inset

.
 Hence,
 we have
\begin_inset Formula 
\[
f(q)\geq f(x)+\left\langle \tilde{g},q-x\right\rangle -\norm{\nabla f(z)-\tilde{g}}_{1}\norm{q-x}_{\infty}-2L\norm{x-z}_{1}.
\]

\end_inset

Note that 
\begin_inset Formula $\norm{x-z}_{1}\leq n\cdot\norm{x-z}_{\infty}\leq n(r_{1}+r_{2})$
\end_inset

 by assumption.
 Moreover,
 we can apply Lemma
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "lem:convex_almost_flat"
nolink "false"

\end_inset

 to bound 
\begin_inset Formula $\norm{\nabla f(z)-\tilde{g}}_{1}$
\end_inset

 and use 
\begin_inset Formula $r_{2}=\sqrt{\frac{\varepsilon r_{1}}{\sqrt{n}L}}\leq r_{1}$
\end_inset

 to get
\begin_inset Formula 
\[
f(q)\geq f(x)+\left\langle \tilde{g},q-x\right\rangle -\zeta\norm{q-x}_{\infty}-4nr_{1}L
\]

\end_inset

with 
\begin_inset Formula $\E\zeta\leq2n^{3/2}\frac{r_{2}}{r_{1}}L$
\end_inset

.
\end_layout

\begin_layout Proof
Since we only compute 
\begin_inset Formula $f$
\end_inset

 up to 
\begin_inset Formula $\varepsilon$
\end_inset

 additive error,
 it introduces 
\begin_inset Formula $\frac{\varepsilon}{r_{2}}$
\end_inset

 additive error in 
\begin_inset Formula $\tilde{g}_{i}$
\end_inset

.
 Hence,
 we instead have that
\begin_inset Formula 
\[
\E\zeta\leq2n^{3/2}\frac{r_{2}}{r_{1}}L+\frac{\varepsilon n}{2r_{2}}.
\]

\end_inset

Setting 
\begin_inset Formula $r_{2}=\frac{1}{2}\sqrt{\frac{\varepsilon r_{1}}{\sqrt{n}L}}$
\end_inset

 completes the proof.
\end_layout

\begin_layout Standard
Note that if we happened to have an exact oracle for 
\begin_inset Formula $f$
\end_inset

,
 then we can make 
\begin_inset Formula $r_{2}$
\end_inset

 arbitrarily small.
\end_layout

\begin_layout Exercise
Suppose in Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:separateFunc"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 we apply the idea of a linear approximation directly to a small box around the query point 
\begin_inset Formula $x$
\end_inset

,
 i.e.,
 we pick a random point 
\begin_inset Formula $z$
\end_inset

,
 avoiding the intermediate point 
\begin_inset Formula $y$
\end_inset

 entirely,
 and use 
\begin_inset Formula $z$
\end_inset

 to find endpoints of chords through 
\begin_inset Formula $z$
\end_inset

 and compute an estimate of the gradient.
 Why is this not accurate in general?
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Exercise
What is the best possible bound in Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:convex_almost_flat"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 in particular is the dependence on the dimension tight?
\end_layout

\begin_layout Standard
In the proof of Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:convex_almost_flat"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 we used the following fact applied to the case when 
\begin_inset Formula $\Omega$
\end_inset

 is a cube.
 In this case,
 the coefficient on the RHS is given by the Cheeger or KLS constant of the cube and is 
\begin_inset Formula $1$
\end_inset

.
 This is an example of an isoperimetric inequality.
 Such inequalities will play an important role later in this book.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:box-poincare"

\end_inset


\begin_inset Argument 1
status open

\begin_layout Plain Layout
\begin_inset Formula $L^{1}$
\end_inset

-Poincar
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
'e
\end_layout

\end_inset

 inequality
\end_layout

\end_inset

 Let 
\begin_inset Formula $\Omega$
\end_inset

 be connected,
 bounded and open.
 Then the following (best-possible) inequality holds for any smooth function 
\begin_inset Formula $f:\Omega\rightarrow\R$
\end_inset

:
\begin_inset Formula 
\[
\norm{f-\frac{1}{\left|\Omega\right|}\int_{\Omega}f(x)\,dx}_{L^{1}(\Omega)}\le\left(\sup_{S\subset\Omega}\frac{2|S||\Omega\setminus S|}{|\partial S||\Omega|}\right)\norm{\nabla f}_{L^{1}(\Omega)}
\]

\end_inset

 where the supremum is over all subsets 
\begin_inset Formula $S$
\end_inset

 s.t.
 
\begin_inset Formula $S$
\end_inset

 and 
\begin_inset Formula $\Omega\setminus S$
\end_inset

 are both connected.
\begin_inset Note Note
status open

\begin_layout Plain Layout
Add figure!
\end_layout

\end_inset


\end_layout

\begin_layout Exercise
Prove the inequality in Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:box-poincare"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 using the classical co-area formula.
\end_layout

\begin_layout Section
Separation via Membership 
\begin_inset CommandInset label
LatexCommand label
name "sec:From-Membership-to"

\end_inset


\end_layout

\begin_layout Standard
In this section,
 we show how to implement a separation oracle for a convex set using a nearly linear number of queries to a membership oracle.
 We divide this into two steps.
 In the first step (Algorithm
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "alg:separateFunc"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 we compute an approximate subgradient of a given Lipschitz convex function.
 Using this,
 in the second step (Algorithm
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "alg:sep_set"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 we compute an approximate separating hyperplane.
 
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $K$
\end_inset

 be a convex body s.t.
 
\begin_inset Formula $B(0,1)\subseteq K\subseteq B(0,R)$
\end_inset

.
 Then,
 for any 
\begin_inset Formula $0<\eta\leq1/2$
\end_inset

,
 we can compute an 
\begin_inset Formula $\eta$
\end_inset

-approximate separation oracle for K using 
\begin_inset Formula $O(n\log(nR/\eta))$
\end_inset

 queries to a membership oracle for 
\begin_inset Formula $K$
\end_inset

.
\end_layout

\begin_layout Standard
Throughout this section,
 let 
\begin_inset Formula $K\subseteq\R^{n}$
\end_inset

 be a convex set that contains 
\begin_inset Formula $B_{2}(0,r)$
\end_inset

 and is contained in 
\begin_inset Formula $B_{2}(0,R)$
\end_inset

.
 Recall that 
\begin_inset Formula $B_{p}(x,r)$
\end_inset

 is the 
\begin_inset Formula $p$
\end_inset

-norm ball of radius 
\begin_inset Formula $r$
\end_inset

 centered at 
\begin_inset Formula $x$
\end_inset

.
 By an approximate separation oracle we mean that either the queried point 
\begin_inset Formula $x$
\end_inset

 lies within distance 
\begin_inset Formula $\eta$
\end_inset

 of 
\begin_inset Formula $K$
\end_inset

,
 or the oracle provides a halfspace 
\begin_inset Formula $c^{T}y\le c^{T}x+\eta$
\end_inset

 for all points 
\begin_inset Formula $y\in K$
\end_inset

 at distance at least 
\begin_inset Formula $\eta$
\end_inset

 from the boundary of 
\begin_inset Formula $K$
\end_inset

.
 We also define 
\begin_inset Formula 
\[
B_{p}(K,-\delta)\defeq\{x\in\R^{n}:B_{p}(x,\delta)\subseteq K\}.
\]

\end_inset

Given some point 
\begin_inset Formula $x\notin K$
\end_inset

,
 we wish to separate 
\begin_inset Formula $x$
\end_inset

 from 
\begin_inset Formula $K$
\end_inset

 using a halfspace.
 To do this,
 we reduce this problem to computing an approximate subgradient of a Lipschitz convex function 
\begin_inset Formula $h_{x}(d)$
\end_inset

 defined for points in 
\begin_inset Formula $K.$
\end_inset

 Roughly speaking,
 it is the 
\begin_inset Quotes eld
\end_inset

height
\begin_inset Quotes erd
\end_inset

 (or distance from the boundary) of a point 
\begin_inset Formula $d$
\end_inset

 in the direction of 
\begin_inset Formula $x$
\end_inset

.
 Let 
\begin_inset Formula 
\[
\alpha_{x}(d)=\max_{d+\alpha x\in K}\alpha\mbox{ \quad and \quad}h_{x}(d)=-\alpha_{x}(d)\norm x_{2}.
\]

\end_inset

 Note that 
\begin_inset Formula $d+\alpha_{x}(d)x$
\end_inset

 is the last point in 
\begin_inset Formula $K$
\end_inset

 on the line through 
\begin_inset Formula $d\in K$
\end_inset

 in the direction of 
\begin_inset Formula $x$
\end_inset

,
 and 
\begin_inset Formula $-h_{x}(d)$
\end_inset

 is the 
\begin_inset Formula $\ell_{2}$
\end_inset

 distance from this boundary point to 
\begin_inset Formula $d$
\end_inset

 (see Fig.
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:height-function"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Figures/Thrm_4.27.png
	width 60col%

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
The convex height function 
\begin_inset Formula $h_{x}$
\end_inset


\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:height-function"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithm2e}[h]
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "alg:sep_set"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
caption{
\end_layout

\end_inset


\begin_inset Formula $\mathtt{Separate}_{\varepsilon,\rho}(K,x)$
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
SetAlgoLined
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
Require:

\series default
 
\begin_inset Formula $B_{2}(0,r)\subset K\subset B_{2}(0,R)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
uIf{
\end_layout

\end_inset


\begin_inset Formula $\text{MEM}_{\varepsilon}(K)$
\end_inset

 asserts that 
\begin_inset Formula $x\in B(K,\epsilon)$
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}{
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
Output:

\series default
 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $x\in B(K,\varepsilon)$
\end_inset


\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

}
\backslash
ElseIf{
\end_layout

\end_inset


\begin_inset Formula $x\notin B_{2}(0,R)$
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}{
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
Output:

\series default
 the halfspace 
\begin_inset Formula $\{y:0\geq\left\langle y-x,x\right\rangle \}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\kappa=R/r$
\end_inset

,
 
\begin_inset Formula $\alpha_{x}(d)=\max_{d+\alpha x\in K}\alpha$
\end_inset

 and 
\begin_inset Formula $h_{x}(d)=-\alpha_{x}(d)\norm x_{2}$
\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Should discuss using approximate 
\begin_inset Formula $\alpha_{x}$
\end_inset

,
 since binary search is not exact.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The evaluation oracle of 
\begin_inset Formula $\alpha_{x}(d)$
\end_inset

 can be implemented via binary search and 
\begin_inset Formula $\text{MEM}_{\varepsilon}(K)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Compute 
\begin_inset Formula $\tilde{g}=\mathtt{SubgradConvexFunc}(h_{x},0,r_{1},4\varepsilon)$
\end_inset

 with 
\begin_inset Formula $r_{1}=n^{1/6}\varepsilon^{1/3}R^{2/3}\kappa^{-1}$
\end_inset

 and the evaluation oracle of 
\begin_inset Formula $\alpha_{x}(d)$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Output:

\series default
 the halfspace
\begin_inset Formula 
\[
\left\{ y:\frac{31}{\rho}n^{7/6}R^{2/3}\kappa\varepsilon^{1/3}\geq\left\langle \tilde{g},y-x\right\rangle \right\} 
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{algorithm2e}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The output of the algorithm for separation is a halfspace that approximately contains 
\begin_inset Formula $K$
\end_inset

,
 and the input point 
\begin_inset Formula $x$
\end_inset

 is close to its bounding hyperplane.
 It uses a call to the subgradient function above.
 
\end_layout

\begin_layout Standard
We now proceed to analyze the height function.
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lem:h_convex"

\end_inset

 
\begin_inset Formula $h_{x}(d)$
\end_inset

 is convex on 
\begin_inset Formula $K$
\end_inset

.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $d_{1},d_{2}\in K$
\end_inset

 and 
\begin_inset Formula $\lambda\in[0,1]$
\end_inset

.
 Now 
\begin_inset Formula $d_{1}+\alpha_{x}(d_{1})x\in K$
\end_inset

 and 
\begin_inset Formula $d_{2}+\alpha_{x}(d_{2})x\in K$
\end_inset

.
 Consequently,
\begin_inset Formula 
\[
\left[\lambda d_{1}+(1-\lambda)d_{2}\right]+\left[\lambda\cdot\alpha_{x}(d_{1})+(1-\lambda)\cdot\alpha_{x}(d_{2})\right]x\in K\,.
\]

\end_inset

Therefore,
 if we let 
\begin_inset Formula $d\defeq\lambda d_{1}+(1-\lambda)d_{2}$
\end_inset

 we see that 
\begin_inset Formula $\alpha_{x}(d)\geq\lambda\cdot\alpha_{x}(d_{1})+(1-\lambda)\cdot\alpha_{x}(d_{2})$
\end_inset

 and 
\begin_inset Formula $h_{x}(\lambda d_{1}+(1-\lambda d_{2})\leq\lambda h_{x}(d_{1})+\lambda h_{x}(d_{2})$
\end_inset

 as claimed.
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lem:h_Lip"

\end_inset

 
\begin_inset Formula $h_{x}$
\end_inset

 is 
\begin_inset Formula $\left(\frac{R+\delta}{r-\delta}\right)$
\end_inset

-Lipschitz over points in 
\begin_inset Formula $B_{2}(0,\delta)$
\end_inset

 for any 
\begin_inset Formula $\delta<r$
\end_inset

.
 
\end_layout

\begin_layout Lemma
\begin_inset Float figure
placement document
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Figures/Lemma_4.29.png
	width 40col%

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $d_{1},d_{2}$
\end_inset

 be arbitrary points in 
\begin_inset Formula $B(0,\delta)$
\end_inset

.
 We wish to upper bound 
\begin_inset Formula $\left|h_{x}(d_{1})-h_{x}(d_{2})\right|$
\end_inset

 in terms of 
\begin_inset Formula $\norm{d_{1}-d_{2}}_{2}$
\end_inset

.
 We assume without loss of generality that 
\begin_inset Formula $\alpha_{x}(d_{1})\geq\alpha_{x}(d_{2})$
\end_inset

 and therefore
\begin_inset Formula 
\[
\left|h_{x}(d_{1})-h_{x}(d_{2})\right|=\left|\alpha_{x}(d_{1})\norm x_{2}-\alpha_{x}(d_{2})\norm x_{2}\right|=\left(\alpha_{x}(d_{1})-\alpha_{x}(d_{2})\right)\norm x_{2}\,.
\]

\end_inset

Consequently,
 it suffices to lower bound 
\begin_inset Formula $\alpha_{x}(d_{2})$
\end_inset

.
 We split the analysis into two cases.
\end_layout

\begin_layout Proof
Case 1:
 
\begin_inset Formula $\norm{d_{2}-d_{1}}_{2}\geq r-\delta$
\end_inset

.
 Since 
\begin_inset Formula $0\geq h_{x}(d_{1}),h_{x}(d_{2})\geq-R-\delta$
\end_inset

,
 we have that 
\begin_inset Formula 
\[
\left|h_{x}(d_{1})-h_{x}(d_{2})\right|\leq R+\delta\leq\frac{R+\delta}{r-\delta}\norm{d_{2}-d_{1}}_{2}.
\]

\end_inset


\end_layout

\begin_layout Proof
Case 2:
 
\begin_inset Formula $\norm{d_{2}-d_{1}}_{2}\leq r-\delta$
\end_inset

.
 We consider the point 
\begin_inset Formula $d_{3}=d_{1}+\frac{d_{2}-d_{1}}{\lambda}$
\end_inset

 with 
\begin_inset Formula $\lambda=\norm{d_{2}-d_{1}}_{2}/(r-\delta)$
\end_inset

.
 Note that 
\begin_inset Formula 
\[
\norm{d_{3}}_{2}\leq\norm{d_{1}}_{2}+\frac{1}{\lambda}\norm{d_{2}-d_{1}}_{2}\leq\delta+\frac{1}{\lambda}\norm{d_{2}-d_{1}}_{2}\leq r.
\]

\end_inset

Hence,
 
\begin_inset Formula $d_{3}\in K$
\end_inset

.
 Since 
\begin_inset Formula $\lambda\in[0,1]$
\end_inset

 and 
\begin_inset Formula $K$
\end_inset

 is convex,
 we have that 
\begin_inset Formula $\lambda\cdot d_{3}+(1-\lambda)\cdot\left[d_{1}+\alpha_{x}(d_{1})x\right]\in K$
\end_inset

.
 Now,
 we note that
\begin_inset Formula 
\[
\lambda\cdot d_{3}+(1-\lambda)\cdot\left[d_{1}+\alpha_{x}(d_{1})x\right]=d_{2}+(1-\lambda)\cdot\alpha_{x}(d_{1})x
\]

\end_inset

and this shows that 
\begin_inset Formula 
\[
\alpha_{x}(d_{2})\geq(1-\lambda)\cdot\alpha_{x}(d_{1})=\left(1-\frac{\norm{d_{2}-d_{1}}_{2}}{r-\delta}\right)\cdot\alpha_{x}(d_{1}).
\]

\end_inset

Since 
\begin_inset Formula $d_{1}+\alpha_{x}(d_{1})x\in K\subset B_{2}(0,R)$
\end_inset

,
 we have that 
\begin_inset Formula $\alpha_{x}(d_{1})\cdot\norm x_{2}\leq R+\delta$
\end_inset

 and hence
\begin_inset Formula 
\[
\left|h_{x}(d_{1})-h_{x}(d_{2})\right|=(\alpha_{x}(d_{1})-\alpha_{x}(d_{2}))\cdot\norm x_{2}\leq\alpha_{x}(d_{1})\cdot\norm x_{2}\frac{\norm{d_{2}-d_{1}}_{2}}{r-\delta}\leq\frac{R+\delta}{r-\delta}\norm{d_{2}-d_{1}}_{2}.
\]

\end_inset

 In either case,
 as claimed we have
\begin_inset Formula 
\[
\left|h_{x}(d_{1})-h_{x}(d_{2})\right|\leq\frac{R+\delta}{r-\delta}\norm{d_{2}-d_{1}}_{2}.
\]

\end_inset


\end_layout

\begin_layout Standard
The next lemma shows that 
\begin_inset Formula $h_{x}$
\end_inset

 gives us a way to implement an approximation separation oracle and only needs access to an approximation evaluation oracle for 
\begin_inset Formula $h_{x}$
\end_inset

 which in turn only needs an approximate membership oracle for 
\begin_inset Formula $K$
\end_inset

.
 To be precise,
 we define approximate oracles.
\end_layout

\begin_layout Definition
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Separation Oracle (SEP)
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "def:SEP-1"

\end_inset

 Queried with a vector 
\begin_inset Formula $y\in\Rn$
\end_inset

 and real numbers 
\begin_inset Formula $\delta,\delta'>0$
\end_inset

,
 with probability at least 
\begin_inset Formula $1-\delta'$
\end_inset

,
 the oracle either
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
assert that 
\begin_inset Formula $y\in B(K,\delta)$
\end_inset

,
 or
\end_layout

\begin_layout Itemize
find a unit vector 
\begin_inset Formula $c\in\Rn$
\end_inset

 such that 
\begin_inset Formula $c^{T}x\leq c^{T}y+\delta$
\end_inset

 for all 
\begin_inset Formula $x\in B(K,-\delta)$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Definition
We let 
\begin_inset Formula $\text{SEP}_{\delta,\delta'}(K)$
\end_inset

 be the time complexity of this oracle.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Membership Oracle (MEM)
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "def:MEM-1"

\end_inset

 Queried with a vector 
\begin_inset Formula $y\in\Rn$
\end_inset

 and real numbers 
\begin_inset Formula $\delta,\delta'>0$
\end_inset

,
 with probability at least 
\begin_inset Formula $1-\delta'$
\end_inset

,
 either
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
assert that 
\begin_inset Formula $y\in B(K,\delta)$
\end_inset

,
 or
\end_layout

\begin_layout Itemize
assert that 
\begin_inset Formula $y\notin B(K,-\delta)$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Definition
We let 
\begin_inset Formula $\text{MEM}_{\delta,\delta'}(K)$
\end_inset

 be the time complexity of this oracle.
\end_layout

\begin_layout Standard
We can now state the main lemma for the separation oracle.
 Since the algorithm is randomized,
 we have a parameter 
\begin_inset Formula $\rho\in(0,1)$
\end_inset

 to denote the probability of failure.
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lem:separate_set"

\end_inset

 Let 
\begin_inset Formula $K$
\end_inset

 be a convex set satisfying 
\begin_inset Formula $B_{2}(0,r)\subset K\subset B_{2}(0,R)$
\end_inset

.
 Given any 
\begin_inset Formula $0<\rho<1$
\end_inset

 and 
\begin_inset Formula $0\leq\varepsilon\leq r$
\end_inset

.
 With probability 
\begin_inset Formula $1-\rho$
\end_inset

,
 
\begin_inset Formula $\mathtt{Separate}_{\varepsilon,\rho}(K,x)$
\end_inset

 outputs a halfspace that contains 
\begin_inset Formula $K$
\end_inset

.
 
\end_layout

\begin_layout Proof
When 
\begin_inset Formula $x\notin B_{2}(0,R)$
\end_inset

,
 the algorithm outputs a valid separation for 
\begin_inset Formula $B_{2}(0,R)$
\end_inset

.
 For the rest of the proof,
 we assume 
\begin_inset Formula $x\notin B(K,-\varepsilon)$
\end_inset

 (due to the membership oracle) and 
\begin_inset Formula $x\in B_{2}(0,R)$
\end_inset

.
\end_layout

\begin_layout Proof
By Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:h_convex"
nolink "false"

\end_inset

 and Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:h_Lip"
nolink "false"

\end_inset

,
 
\begin_inset Formula $h_{x}$
\end_inset

 is convex with Lipschitz constant 
\begin_inset Formula $3\kappa$
\end_inset

 on 
\begin_inset Formula $B_{2}(0,\frac{r}{2})$
\end_inset

.
 By our assumption on 
\begin_inset Formula $\varepsilon$
\end_inset

 and our choice of 
\begin_inset Formula $r_{1}$
\end_inset

,
 we have that 
\begin_inset Formula $B_{\infty}(0,2r_{1})\subset B_{2}(0,\frac{r}{2})$
\end_inset

.
 Hence,
 we can apply Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:separate_conv_func"
nolink "false"

\end_inset

 to get that
\begin_inset Formula 
\begin{align}
h_{x}(y) & \geq h_{x}(0)+\left\langle \tilde{g},y\right\rangle -\zeta\norm y_{\infty}-12nr_{1}\kappa\label{eq:hxy-1}
\end{align}

\end_inset

for any 
\begin_inset Formula $y\in K$
\end_inset

.
 Note that 
\begin_inset Formula $-\frac{x}{\kappa}\in K$
\end_inset

 and 
\begin_inset Formula $h_{x}(-\frac{x}{\kappa})=h_{x}(0)-\frac{1}{\kappa}\norm x_{2}$
\end_inset

.
 Hence,
 we have
\begin_inset Formula 
\[
h_{x}(0)-\frac{1}{\kappa}\norm x_{2}=h_{x}(-\frac{1}{\kappa}x)\geq h_{x}(0)+\left\langle \tilde{g},-\frac{1}{\kappa}x\right\rangle -\frac{1}{\kappa}\zeta\norm x_{\infty}-12nr_{1}\kappa.
\]

\end_inset

Therefore,
 we have
\begin_inset Formula 
\begin{equation}
\left\langle \tilde{g},x\right\rangle \geq\norm x_{2}-\zeta\norm x_{\infty}-12nr_{1}\kappa^{2}.\label{eq:lowerbound_g}
\end{equation}

\end_inset

Now,
 we note that 
\begin_inset Formula $x\notin B(K,-\varepsilon)$
\end_inset

.
 Using that 
\begin_inset Formula $B(0,r)\subset K$
\end_inset

,
 we have 
\begin_inset Formula $(1-\frac{\varepsilon}{r})K\subset B(K,-\varepsilon)$
\end_inset

.
 Hence,
 
\begin_inset Formula 
\[
h_{x}(0)\geq-\left(1-\frac{\varepsilon}{r}\right)\norm x_{2}\geq-\norm x_{2}.
\]

\end_inset

Therefore,
 we have
\begin_inset Formula 
\[
h_{x}(0)+\left\langle \tilde{g},x\right\rangle \geq-\zeta\norm x_{\infty}-12nr_{1}\kappa^{2}
\]

\end_inset

Combining this with 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:hxy-1"
nolink "false"

\end_inset

,
 we have that 
\begin_inset Formula 
\begin{align*}
h_{x}(y) & \geq\left\langle \tilde{g},y-x\right\rangle -\zeta\norm y_{\infty}-\zeta\norm x_{\infty}-12nr_{1}\kappa-12nr_{1}\kappa^{2}\\
 & \geq\left\langle \tilde{g},y-x\right\rangle -2\zeta R-24nr_{1}\kappa^{2}
\end{align*}

\end_inset

for any 
\begin_inset Formula $y\in K$
\end_inset

.
 Recall from Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:separate_conv_func"
nolink "false"

\end_inset

 that 
\begin_inset Formula $\zeta$
\end_inset

 is a positive random scalar independent of 
\begin_inset Formula $y$
\end_inset

 satisfying 
\begin_inset Formula $\E\zeta\leq2\sqrt{\frac{3\kappa\varepsilon}{r_{1}}}n^{5/4}$
\end_inset

.
 For any 
\begin_inset Formula $y\in K$
\end_inset

,
 we have that 
\begin_inset Formula $h_{x}(y)\leq0$
\end_inset

 and hence 
\begin_inset Formula $\tilde{\zeta}\geq\left\langle \tilde{g},y-x\right\rangle $
\end_inset

 where 
\begin_inset Formula $\tilde{\zeta}$
\end_inset

 is a random scalar independent of 
\begin_inset Formula $y$
\end_inset

 satisfying 
\begin_inset Formula 
\begin{align*}
\E\tilde{\zeta} & \le4\sqrt{\frac{3\kappa\varepsilon}{r_{1}}}n^{5/4}R+24nr_{1}\kappa^{2}\\
 & \leq31n^{7/6}R^{2/3}\varepsilon^{1/3}\kappa.
\end{align*}

\end_inset

where we used 
\begin_inset Formula $r_{1}=n^{1/6}\varepsilon^{1/3}R^{2/3}/\kappa$
\end_inset

 and 
\begin_inset Formula $0\leq\varepsilon\leq r$
\end_inset

.
 The result then follows using Markov's inequality.
 
\end_layout

\begin_layout Exercise
Suppose we can evaluate the subgradient of 
\begin_inset Formula $h_{x}$
\end_inset

 exactly for a convex set 
\begin_inset Formula $K$
\end_inset

 containing the origin.
 Give a short proof that for any 
\begin_inset Formula $x\not\in K$
\end_inset

,
 we have 
\begin_inset Formula $\langle\nabla h_{x}(0),y-x\rangle\le0$
\end_inset

 for all 
\begin_inset Formula $y\in K$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:separate_set"

\end_inset

 Let 
\begin_inset Formula $K$
\end_inset

 be a convex set satisfying 
\begin_inset Formula $B_{2}(0,1/\kappa)\subset K\subset B_{2}(0,1)$
\end_inset

.
 For any 
\begin_inset Formula $0\leq\eta<\frac{1}{2}$
\end_inset

,
 we have that
\begin_inset Formula 
\[
\text{SEP}_{\eta}(K)\leq O\left(n\log\left(\frac{n\kappa}{\eta}\right)\right)\text{MEM}_{(\eta/n\kappa)^{O(1)}}(K).
\]

\end_inset


\end_layout

\begin_layout Proof
First,
 we bound the running time.
 Note that the bottleneck is to compute 
\begin_inset Formula $h_{x}$
\end_inset

 with 
\begin_inset Formula $\delta$
\end_inset

 additive error.
 Since 
\begin_inset Formula $-O(1)\leq h_{x}(y)\leq0$
\end_inset

 for all 
\begin_inset Formula $y\in B_{2}(0,O(1))$
\end_inset

,
 one can compute 
\begin_inset Formula $h_{x}(y)$
\end_inset

 by binary search with 
\begin_inset Formula $O(\log(1/\delta))$
\end_inset

 calls to the membership oracle.
\end_layout

\begin_layout Proof
Next,
 we check that 
\begin_inset Formula $\mathtt{Separate}_{\delta,\rho}(K,x)$
\end_inset

 is indeed a separation oracle.
 Note that 
\begin_inset Formula $\tilde{g}$
\end_inset

 may not be an unit vector and we need to re-normalize the 
\begin_inset Formula $\tilde{g}$
\end_inset

 by 
\begin_inset Formula $1/\norm{\tilde{g}}_{2}$
\end_inset

.
 So,
 we need to a lower bound 
\begin_inset Formula $\norm{\tilde{g}}_{2}$
\end_inset

.
 
\end_layout

\begin_layout Proof
From 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:lowerbound_g"
nolink "false"

\end_inset

 and our choice of 
\begin_inset Formula $r_{1}$
\end_inset

,
 if we set 
\begin_inset Formula $\varepsilon=\delta$
\end_inset

,
 where 
\begin_inset Formula $\delta$
\end_inset

 is the error and 
\begin_inset Formula $\rho$
\end_inset

 is the failure probability of the separation oracle,
 then we have that
\begin_inset Formula 
\begin{align*}
\left\langle \tilde{g},x\right\rangle  & \geq\norm x_{2}-\zeta\norm x_{\infty}-12nr_{1}\kappa^{2}\geq\frac{r}{4}.
\end{align*}

\end_inset

Hence,
 we have that 
\begin_inset Formula $\norm{\tilde{g}}_{2}\geq\frac{1}{4\kappa}$
\end_inset

.
 Therefore,
 this algorithm is a separation oracle with error 
\begin_inset Formula $\frac{400}{\rho}n^{7/6}\kappa^{2}\delta^{1/3}$
\end_inset

 and by the union bound,
 with failure probability 
\begin_inset Formula $O(\rho+\log(1/\delta)\delta)$
\end_inset

.
 Therefore,
\begin_inset Formula 
\[
\text{SEP}_{\Omega(\max(n^{7/6}\kappa^{2}\delta^{1/3}/\rho+\rho+\log(1/\delta)\delta)}(K)\leq O(\log(1/\delta))\text{MEM}_{\delta}(K).
\]

\end_inset

Setting 
\begin_inset Formula $\rho=\sqrt{n^{7/6}\kappa^{2}\delta^{1/3}}$
\end_inset

 and 
\begin_inset Formula $\delta=\Theta\left(\frac{\eta^{6}}{n^{7/2}\kappa^{6}}\right)$
\end_inset

,
 we have that 
\begin_inset Formula 
\[
\text{SEP}_{\eta}(K)\leq O(\log(\frac{n\kappa}{\eta}))\text{MEM}_{\eta^{6}/(n^{7/2}\kappa^{6})}(K).
\]

\end_inset


\end_layout

\begin_layout Subsection
Gradient from Evaluation via Auto Differentiation 
\end_layout

\begin_layout Standard
In this section,
 we give yet another way to compute gradients using evaluations.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:auto_diff"

\end_inset

 Given a function 
\begin_inset Formula $f:\R^{n}\rightarrow\R$
\end_inset

 represented by an circuit whose gates compute differentiable functions of a finite number of variables.
 Suppose that 
\begin_inset Formula $f(x)$
\end_inset

 can be computed in time 
\begin_inset Formula $\mathcal{T}$
\end_inset

 (namely,
 the circuit has 
\begin_inset Formula $\mathcal{T}$
\end_inset

 edges).
 Then we can compute 
\begin_inset Formula $\nabla f(x)$
\end_inset

 in 
\begin_inset Formula $O(\mathcal{T})$
\end_inset

 time.
\end_layout

\begin_layout Remark*
In practice,
 the runtime is roughly 
\begin_inset Formula $2\mathcal{T}$
\end_inset

 assuming we have enough memory.
 Check out google/jax for a modern implementation.
\end_layout

\begin_layout Remark*
Before proving it formally,
 we first go through an example.
 Consider the function 
\begin_inset Formula $f(x_{1},x_{2})=\sin(x_{1}/x_{2})+x_{1}x_{2}$
\end_inset

.
 We use 
\begin_inset Formula $x_{i}$
\end_inset

 to denote both the input and all intermediate variables.
 Then,
 we can write the program in 
\begin_inset Formula $\mathcal{T}=6$
\end_inset

 steps:
\end_layout

\begin_layout Itemize
\begin_inset Formula $x_{1}=x_{1}$
\end_inset

,
 
\begin_inset Formula $x_{2}=x_{2}$
\end_inset

,
 
\begin_inset Formula $x_{3}=x_{1}/x_{2}$
\end_inset

,
 
\begin_inset Formula $x_{4}=\sin(x_{3})$
\end_inset

,
 
\begin_inset Formula $x_{5}=x_{1}x_{2}$
\end_inset

,
 Output 
\begin_inset Formula $x_{6}=x_{4}+x_{5}$
\end_inset

.
\end_layout

\begin_layout Standard
Note that each step involves computing
\begin_inset Formula 
\[
x_{i}=f_{i}(\overset{\text{only few }x_{j}}{\overbrace{x_{1},\cdots,x_{i-1}}})
\]

\end_inset

with simple functions 
\begin_inset Formula $f_{i}$
\end_inset

 whose derivatives we know how to compute.
 The key idea is compute 
\begin_inset Formula $\frac{\partial f}{\partial x_{1}}$
\end_inset

 not just for the inputs 
\begin_inset Formula $x_{1}$
\end_inset

 and 
\begin_inset Formula $x_{2}$
\end_inset

,
 but also for all intermediate variables.
 Here,
 we use 
\begin_inset Formula $\frac{\partial f}{\partial x_{i}}$
\end_inset

 to denote the derivative of 
\begin_inset Formula $f$
\end_inset

 with respect to 
\begin_inset Formula $x_{i}$
\end_inset

 while fixing 
\begin_inset Formula $x_{1},x_{2},\cdots,x_{i-1}$
\end_inset

 (and other inputs if 
\begin_inset Formula $x_{i}$
\end_inset

 is an input).
 For the example above,
 suppose we want to compute 
\begin_inset Formula $\nabla f(\pi,2)$
\end_inset

,
 we can simply compute first compute all 
\begin_inset Formula $x_{i}$
\end_inset

 from 
\begin_inset Formula $i=1,2,\cdots,6$
\end_inset

,
 then 
\begin_inset Formula $\frac{\partial f}{\partial x_{i}}$
\end_inset

 in the reverse order from 
\begin_inset Formula $i=6,5,\cdots,1$
\end_inset

:
\end_layout

\begin_layout Itemize
\begin_inset Formula $x_{1}=\pi$
\end_inset

,
 
\begin_inset Formula $x_{2}=2$
\end_inset

,
 
\begin_inset Formula $x_{3}=\pi/2$
\end_inset

,
 
\begin_inset Formula $x_{4}=\sin(x_{3})=1$
\end_inset

,
 
\begin_inset Formula $x_{5}=x_{1}x_{2}=2\pi$
\end_inset

,
 
\begin_inset Formula $x_{6}=x_{4}+x_{5}=2\pi+1$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $\frac{\partial f}{\partial x_{6}}=1$
\end_inset

,
 
\begin_inset Formula $\frac{\partial f}{\partial x_{5}}=\frac{\partial\left(x_{4}+x_{5}\right)}{\partial x_{5}}=1$
\end_inset

,
 
\begin_inset Formula $\frac{\partial f}{\partial x_{4}}=\frac{\partial\left(x_{4}+x_{5}\right)}{\partial x_{4}}=1$
\end_inset

,
\end_layout

\begin_layout Itemize
\begin_inset Formula $\frac{\partial f}{\partial x_{3}}=\frac{\partial f}{\partial x_{4}}\frac{\partial x_{4}}{\partial x_{3}}=1\cdot\cos(x_{3})=0$
\end_inset

,
\end_layout

\begin_layout Itemize
\begin_inset Formula $\frac{\partial f}{\partial x_{2}}=\frac{\partial f}{\partial x_{3}}\frac{\partial x_{3}}{\partial x_{2}}+\frac{\partial f}{\partial x_{5}}\frac{\partial x_{5}}{\partial x_{2}}=0\cdot(-\frac{x_{1}}{x_{2}^{2}})+1\cdot x_{1}=\pi$
\end_inset

,
\end_layout

\begin_layout Itemize
\begin_inset Formula $\frac{\partial f}{\partial x_{1}}=\frac{\partial f}{\partial x_{3}}\frac{\partial x_{3}}{\partial x_{1}}+\frac{\partial f}{\partial x_{5}}\frac{\partial x_{5}}{\partial x_{1}}=0\cdot(\frac{1}{x_{2}})+1\cdot x_{2}=2$
\end_inset

.
\end_layout

\begin_layout Standard
The general case is similar.
 See 
\begin_inset Formula $\mathtt{AutoDifferentiation}$
\end_inset

 for the algorithm.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithm2e}[H]
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
caption{
\end_layout

\end_inset


\begin_inset Formula $\mathtt{AutoDifferentiation}$
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
SetAlgoLined
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
Input:

\series default
 a function 
\begin_inset Formula $f(x_{1},x_{2},\cdots,x_{n})$
\end_inset

 given by 
\begin_inset Formula $f(x_{1},x_{2},\cdots,x_{n})=x_{m}$
\end_inset

 and
\begin_inset Formula 
\[
x_{i}=f_{i}(x_{1},\cdots,x_{i-1})\text{ for }i=n+1,n+2,\cdots,m
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
For{
\end_layout

\end_inset


\begin_inset Formula $i=n+1,n+2,\cdots,m$
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}{
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Compute 
\begin_inset Formula $x_{i}=f_{i}(x_{1},\cdots,x_{i-1})$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\frac{\partial f}{\partial x_{m}}=1$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
For{
\end_layout

\end_inset


\begin_inset Formula $i=m-1,\cdots,1$
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

}{
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $L_{i}$
\end_inset

 be the set of 
\begin_inset Formula $j$
\end_inset

 such that 
\begin_inset Formula $f_{j}$
\end_inset

 depends on 
\begin_inset Formula $x_{i}$
\end_inset

 (i.e.
 
\begin_inset Formula $x_{j}$
\end_inset

 directly depends on 
\begin_inset Formula $x_{i}$
\end_inset

).
\end_layout

\begin_layout Standard
Compute 
\begin_inset Formula $\frac{\partial f}{\partial x_{i}}=\sum_{j\in L_{i}}\frac{\partial f}{\partial x_{j}}\frac{\partial x_{j}}{\partial x_{i}}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{algorithm2e}
\end_layout

\end_inset


\end_layout

\begin_layout Proof
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Proof of Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:auto_diff"
nolink "false"

\end_inset


\end_layout

\end_inset

We prove by induction that the formula 
\begin_inset Formula $\frac{\partial f}{\partial x_{i}}=\sum_{j\in L_{i}}\frac{\partial f}{\partial x_{j}}\frac{\partial x_{j}}{\partial x_{i}}$
\end_inset

 is correct.
 For the base case 
\begin_inset Formula $i=m$
\end_inset

,
 we have 
\begin_inset Formula $f=x_{m}$
\end_inset

 and hence 
\begin_inset Formula $\frac{\partial f}{\partial x_{m}}=1$
\end_inset

.
 For the induction,
 we let 
\begin_inset Formula $L_{i}=\{x_{j_{1}},x_{j_{2}},\cdots,x_{j_{k}}\}$
\end_inset

.
 If we fix variables 
\begin_inset Formula $x_{1},x_{2},\cdots,x_{i-1}$
\end_inset

,
 then 
\begin_inset Formula $f$
\end_inset

 is a function of 
\begin_inset Formula $x_{i}$
\end_inset

 (and of other inputs if 
\begin_inset Formula $x_{i}$
\end_inset

 is an input).
 Since only 
\begin_inset Formula $x_{j_{1}},x_{j_{2}},\cdots,x_{j_{k}}$
\end_inset

 depend on 
\begin_inset Formula $x_{i}$
\end_inset

,
 we can also view 
\begin_inset Formula $f$
\end_inset

 as a function of 
\begin_inset Formula $x_{j_{1}},x_{j_{2}},\cdots,x_{j_{k}}$
\end_inset

.
 More precisely,
 we have
\begin_inset Formula 
\[
f(x_{i})=f(x_{j_{1}}(x_{i},x_{j_{-1}}),x_{j_{2}}(x_{i},x_{j_{-2}}),\cdots,x_{j_{k}}(x_{i},x_{j_{-k}}))
\]

\end_inset

where we use 
\begin_inset Formula $x_{j_{-1}}$
\end_inset

 to denote the variables 
\begin_inset Formula $x_{j_{2}},x_{j_{3}},\cdots,x_{j_{k}}$
\end_inset

.
 By chain rule,
 we have
\begin_inset Formula 
\[
\frac{\partial f}{\partial x_{i}}=\sum_{j\in L_{i}}\frac{\partial f}{\partial x_{j}}\frac{\partial x_{j}}{\partial x_{i}}.
\]

\end_inset


\end_layout

\begin_layout Proof
To bound the runtime,
 we define the computation graph 
\begin_inset Formula $G$
\end_inset

 be a graph on 
\begin_inset Formula $x_{1},x_{2},\cdots,x_{m}$
\end_inset

 such that 
\begin_inset Formula $i\rightarrow j$
\end_inset

 if 
\begin_inset Formula $f_{j}$
\end_inset

 depends on 
\begin_inset Formula $x_{i}$
\end_inset

.
 Note that each edge is examined 
\begin_inset Formula $O(1)$
\end_inset

 times whether evaluating 
\begin_inset Formula $f$
\end_inset

 or its gradient.
 Hence,
 the cost of computing 
\begin_inset Formula $f$
\end_inset

 and the cost of our algorithm are both 
\begin_inset Formula $\Theta(m)$
\end_inset

 where 
\begin_inset Formula $m$
\end_inset

 is the number of edges in 
\begin_inset Formula $G$
\end_inset

.
 This completes the proof.
 
\end_layout

\begin_layout Standard
We note that an efficient implementation of the chain rule is the heart of the backpropagation algorithm fo neural networks.
 To conclude this section,
 we see that Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:auto_diff"
nolink "false"

\end_inset

 can be surprisingly useful even for some simple explicit functions.
\end_layout

\begin_layout Corollary
If we can compute 
\begin_inset Formula $f(A)=\det A$
\end_inset

 exactly in time 
\begin_inset Formula $\mathcal{T}$
\end_inset

,
 then we can compute 
\begin_inset Formula $A^{-1}$
\end_inset

 exactly in 
\begin_inset Formula $O(\mathcal{T})$
\end_inset

.
\end_layout

\begin_layout Proof
Note that 
\begin_inset Formula $\frac{\partial}{\partial A_{ij}}\det A=\text{adj}(A)_{ji}=\det A\cdot(A^{-1})_{ji}$
\end_inset

.
 Hence,
 
\begin_inset Formula $\nabla\log\det A=A^{-\top}$
\end_inset

.
 Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:auto_diff"
nolink "false"

\end_inset

 shows that computing 
\begin_inset Formula $A^{-\top}$
\end_inset

 can be done as fast as 
\begin_inset Formula $\det A$
\end_inset

.
\end_layout

\begin_layout Subsection
Gradient from Evaluation via Complex Step Differentiation
\end_layout

\begin_layout Standard
Auto differentiation is great if the function can be computed exactly.
 However,
 it does not work well if 
\begin_inset Formula $f$
\end_inset

 can be only approximated or the computation of 
\begin_inset Formula $f$
\end_inset

 involves too many variables.
 For example,
 if 
\begin_inset Formula $f$
\end_inset

 is the energy usage of some aircraft design,
 then 
\begin_inset Formula $f$
\end_inset

 can only be computed approximately via simulation and such computation is memory expensive (if we need to store all intermediate variables) and not exact,
 so the method in the previous subsection is not practical.
\end_layout

\begin_layout Standard
To introduce complex step differentiation,
 we recall the formula of finite difference:
\end_layout

\begin_layout Itemize
Forward/Backward difference:
 
\begin_inset Formula $\frac{f(x\pm h)-f(x)}{\pm h}=f'(x)+hf''(\zeta)$
\end_inset

.
\end_layout

\begin_layout Itemize
Central difference:
 
\begin_inset Formula $\frac{f(x+h)-f(x-h)}{2h}=f'(x)+O(h^{2})f'''(\zeta)$
\end_inset

.
\end_layout

\begin_layout Standard
Note that the error analysis above assumes no numerical error involved.
 The formula involves subtracting two close numbers and dividing by a small number and this step creates lots of error.
 If we are computing 
\begin_inset Formula $f$
\end_inset

 as floating point,
 we have
\begin_inset Formula 
\[
\frac{(1\pm\epsilon)f(x\pm h)-(1\pm\epsilon)f(x)}{\pm h}=f'(x)+O(\frac{\epsilon}{h})f(\zeta_{1})+O(h)f''(\zeta_{2})
\]

\end_inset


\begin_inset Formula 
\[
\frac{(1\pm\epsilon)f(x+h)-(1\pm\epsilon)f(x-h)}{2h}=f'(x)+O(\frac{\epsilon}{h})f(\zeta_{1})+O(h^{2})f'''(\zeta_{2})
\]

\end_inset

where 
\begin_inset Formula $\epsilon$
\end_inset

 is the floating point precision.
 Suppose that 
\begin_inset Formula $f,f',f'',f'''$
\end_inset

 are all bounded by constants and suppose 
\begin_inset Formula $\epsilon=(10)^{-8}$
\end_inset

 (single precision floating point),
 then we should pick 
\begin_inset Formula $h=\sqrt{\epsilon}$
\end_inset

 for the first case and 
\begin_inset Formula $h=\epsilon^{1/3}$
\end_inset

 in the second case.
 Hence,
 forward/backward difference gives only accuracy 
\begin_inset Formula $\epsilon^{1/2}\approx(10)^{-4}$
\end_inset

 and the central difference gives only accuracy 
\begin_inset Formula $\epsilon^{2/3}\approx(10)^{-5}$
\end_inset

.
 In reality,
 the error will be larger because 
\begin_inset Formula $f''$
\end_inset

 and 
\begin_inset Formula $f'''$
\end_inset

 usually are large.
\end_layout

\begin_layout Standard
The complex step differentiation uses the step
\begin_inset Formula 
\[
\frac{\mathrm{Im}f(x+ih)}{h}\approx f'(x)+O(h^{2})f''(\zeta).
\]

\end_inset

This formula works only for complex analytic functions,
 but it avoids subtracting numbers.
 In practice,
 this really allows us to compute 
\begin_inset Formula $f'(x)$
\end_inset

 close to machine accuracy.
 In general,
 ensuring algorithms give close to machine accuracy is important because algorithms often stack on top of each other.
\end_layout

\end_body
\end_document
